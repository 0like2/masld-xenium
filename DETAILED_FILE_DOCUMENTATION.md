# ğŸ“š Xenium Benchmarking Project - íŒŒì¼ ë‚´ë¶€ êµ¬ì¡° ì™„ì „ ë¶„ì„

## ğŸ“– ëª©ì°¨
1. [SECTION 1: xb/ í•µì‹¬ Python ëª¨ë“ˆ](#section-1-xb-í•µì‹¬-python-ëª¨ë“ˆ)
2. [SECTION 2: 5_segmentation_benchmark ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬](#section-2-5_segmentation_benchmark-ì„¸ê·¸ë¨¼í…Œì´ì…˜-ë²¤ì¹˜ë§ˆí¬)
3. [SECTION 3: ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬ ìœ í‹¸ë¦¬í‹°](#section-3-ì„¸ê·¸ë¨¼í…Œì´ì…˜-ë²¤ì¹˜ë§ˆí¬-ìœ í‹¸ë¦¬í‹°)

---

## SECTION 1: xb/ í•µì‹¬ Python ëª¨ë“ˆ

### ğŸ“„ xb/formatting.py (38KB) - Xenium ë°ì´í„° í¬ë§· ë³€í™˜

**íŒŒì¼ êµ¬ì¡°**:
```
formatting.py
â”œâ”€â”€ import ì„¹ì…˜ (numpy, pandas, scanpy, gzip, tifffile ë“±)
â”œâ”€â”€ format_xenium_adata()          â† 2022 ë²„ì „ìš©
â”œâ”€â”€ format_xenium_adata_2023()     â† early 2023ìš©
â”œâ”€â”€ format_xenium_adata_mid_2023() â† mid-2023+ ìš©
â”œâ”€â”€ format_background()             â† ë°°ê²½ ì´ë¯¸ì§€ ì²˜ë¦¬
â””â”€â”€ cell_area()                     â† ì„¸í¬ ë©´ì  ê³„ì‚°
```

#### í•¨ìˆ˜ 1: `format_xenium_adata(path, tag, output_path)`

**ì…ë ¥**:
```python
path = "/data/xenium_sample_001/"  # Xenium ê¸°ê³„ ì¶œë ¥ ê²½ë¡œ
tag = "sample_001"                   # ìƒ˜í”Œ ID
output_path = "/output/"             # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
```

**ë‚´ë¶€ ë™ì‘**:

##### 1ë‹¨ê³„: ì••ì¶• í•´ì œ (gzip â†’ raw files)
```python
# ì••ì¶•ëœ íŒŒì¼ë“¤ì„ í’€ê¸°
with gzip.open(path+'/transcripts.csv.gz', 'rb') as f_in:
    with open(path+'/transcripts.csv', 'wb') as f_out:
        shutil.copyfileobj(f_in, f_out)
# transcripts.csv.gz, barcodes.tsv.gz, features.tsv.gz, matrix.mtx.gz ë“± í’€ê¸°
```

**ì²˜ë¦¬ íŒŒì¼ë“¤**:
- `transcripts.csv.gz` â†’ ë¦¬ë“œ ìœ„ì¹˜ ë° ìœ ì „ì ì •ë³´
- `cell_feature_matrix/barcodes.tsv.gz` â†’ ì„¸í¬ ID
- `cell_feature_matrix/features.tsv.gz` â†’ ìœ ì „ì ì •ë³´
- `cell_feature_matrix/matrix.mtx.gz` â†’ í¬ì†Œ í–‰ë ¬ (ì„¸í¬Ã—ìœ ì „ì ì¹´ìš´íŠ¸)
- `cells.csv.gz` â†’ ì„¸í¬ ë©”íƒ€ë°ì´í„° (ì¢Œí‘œ, ë©´ì  ë“±)

##### 2ë‹¨ê³„: ë°ì´í„° ì½ê¸°
```python
# MTX í˜•ì‹ (Matrix Market) ì½ê¸° - í¬ì†Œ í–‰ë ¬ í¬ë§·
a = mmread(path+'/cell_feature_matrix/matrix.mtx')  # í¬ì†Œ í–‰ë ¬
ad = a.todense()  # ì¡°ë°€ í–‰ë ¬ë¡œ ë³€í™˜

# ë©”íƒ€ë°ì´í„° ì½ê¸°
cell_info = pd.read_csv(path+"/cells.csv")
# ê²°ê³¼: DataFrame with columns [cell_id, x_centroid, y_centroid, area, ...]

features = pd.read_csv(path+'/cell_feature_matrix/features.tsv', sep='\t', ...)
# ê²°ê³¼: ìœ ì „ì ì •ë³´ (gene_id, description)
```

**cell_info ì˜ˆì‹œ**:
```
  cell_id  x_centroid  y_centroid  nucleus_area
0     1       100.5      200.3      250.2
1     2       102.1      205.8      245.5
2     3       98.9       202.1      260.1
...
```

##### 3ë‹¨ê³„: AnnData ê°ì²´ ìƒì„±
```python
# AnnData êµ¬ì„±
adata = sc.AnnData(
    ad.transpose(),      # ì „ì¹˜ (ìœ ì „ì Ã— ì„¸í¬ â†’ ì„¸í¬ Ã— ìœ ì „ì)
    obs=cell_info,       # ì„¸í¬ ë©”íƒ€ë°ì´í„°
    var=features         # ìœ ì „ì ë©”íƒ€ë°ì´í„°
)

# ê²°ê³¼: adata.shape = (ì„¸í¬ ìˆ˜, ìœ ì „ì ìˆ˜)
# ì˜ˆ: (10000, 300) - 10,000ê°œ ì„¸í¬, 300ê°œ ìœ ì „ì
```

##### 4ë‹¨ê³„: ê³µê°„ ì •ë³´ ì¶”ê°€
```python
# ê³µê°„ ì¢Œí‘œ ì €ì¥
adata.obsm['spatial'] = np.array(adata.obs.loc[:, ['x_centroid', 'y_centroid']])
# obsm['spatial']: (n_cells, 2) ë°°ì—´ - ê° ì„¸í¬ì˜ X, Y ì¢Œí‘œ
```

**obsm êµ¬ì¡°**:
```
adata.obsm['spatial']:
array([[100.5, 200.3],
       [102.1, 205.8],
       [98.9,  202.1],
       ...])
```

##### 5ë‹¨ê³„: ìœ ì „ì ì£¼ì„ ì¶”ê°€
```python
# Panel ì •ë³´ë¡œë¶€í„° ì£¼ì„ ì¶”ê°€
panel_info = pd.read_csv(path+'/panel.tsv', sep='\t')
# panel_info columns: [Gene, Annotation, Ensembl ID, ...]

dict_annotation = dict(zip(panel_info['Gene'], panel_info['Annotation']))
dict_ENSEMBL = dict(zip(panel_info['Gene'], panel_info['Ensembl ID']))

adata.var['Annotation'] = adata.var.index.map(dict_annotation)
adata.var['Ensembl ID'] = adata.var.index.map(dict_ENSEMBL)
adata.var['in_panel'] = adata.var.index.isin(panel_info['Gene'])
```

**var (ìœ ì „ì) ë©”íƒ€ë°ì´í„°**:
```
         gene_id  reason_of_inclusion  Annotation  Ensembl ID  in_panel
GAPDH   GAPDH    in_panel            Housekeeping  ENSG00000111640  True
VIP     VIP      in_panel            Neuropeptide  ENSG00000125686  True
```

##### 6ë‹¨ê³„: ë°°ê²½ ì´ë¯¸ì§€ ì²˜ë¦¬
```python
# DAPI ì´ë¯¸ì§€ ì½ê¸° ë° ë¦¬ì‚¬ì´ì¦ˆ
IM = tf.TiffFile(path+'/background.tiff')
position1 = IM.series[0].asarray()  # TIFF ì½ê¸°

# ì´ë¯¸ì§€ ë‹¤ìš´ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ ì ˆì•½)
image_downsize_fact = 1/(2000/np.max(position1.shape))
pos1_resized = np.resize(position1,
                         (position1.shape/image_downsize_fact).astype(int))
```

**ì´ë¯¸ì§€ ì •ë³´**:
- ì›ë³¸: 2048Ã—2048 or 4096Ã—4096 í”½ì…€
- ë¦¬ì‚¬ì´ì¦ˆë¨: 2000 í”½ì…€ ê¸°ì¤€ìœ¼ë¡œ ì¶•ì†Œ
- ëª©ì : ì‹œê°í™” ë° ë©”íƒ€ë°ì´í„° ì €ì¥

##### 7ë‹¨ê³„: Xenium ë©”íƒ€ë°ì´í„° ì €ì¥
```python
# uns (unstructured) ì •ë³´ ì €ì¥
adata.uns = {
    "spatial": {
        tag: {
            "scalefactors": {
                "tissue_um_to_pixel": 1/0.2125,  # Î¼m to pixel ë³€í™˜
                "tissue_hires_scalef": 1/(0.2125*image_downsize_fact)
            },
            "images": {
                "hires": pos1_resized  # ë°°ê²½ ì´ë¯¸ì§€
            }
        }
    }
}
adata.uns['spots'] = transcripts  # ë¦¬ë“œ ë ˆë²¨ ì •ë³´
```

**scalefactors ì˜ë¯¸**:
- `tissue_um_to_pixel`: 1 ë§ˆì´í¬ë¡œë¯¸í„° = ? í”½ì…€
- ì˜ˆ: 0.2125 Î¼m/í”½ì…€ = 1/0.2125 = 4.7 í”½ì…€/Î¼m
- ì‚¬ìš©: ë§ˆì´í¬ë¡œë¯¸í„° ë‹¨ìœ„ ê±°ë¦¬ë¥¼ í”½ì…€ë¡œ ë³€í™˜í•  ë•Œ

##### 8ë‹¨ê³„: ì¶”ê°€ ì°¨ì› ì¶•ì†Œ ë°ì´í„° ë¡œë“œ
```python
# Xenium ê¸°ê³„ê°€ ì‚¬ì „ ê³„ì‚°í•œ ê²°ê³¼ ë¡œë“œ
try:
    UMAP = pd.read_csv(path+'/analysis/umap/.../projection.csv', index_col=0)
    adata.obsm['X_umap'] = np.array(UMAP)

    TSNE = pd.read_csv(path+'/analysis/tsne/.../projection.csv', index_col=0)
    adata.obsm['X_tsne'] = np.array(TSNE)

    PCA = pd.read_csv(path+'/analysis/PCA/.../projection.csv', index_col=0)
    adata.obsm['X_pca'] = np.array(PCA)
except:
    print('ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
```

**obsm ì»¬ë ‰ì…˜**:
```
adata.obsm:
  - 'spatial': (n_cells, 2) - ê³µê°„ ì¢Œí‘œ
  - 'X_umap': (n_cells, 2) - UMAP
  - 'X_tsne': (n_cells, 2) - t-SNE
  - 'X_pca': (n_cells, 10) - PCA (10 ì„±ë¶„)
```

##### 9ë‹¨ê³„: í´ëŸ¬ìŠ¤í„°ë§ ì •ë³´ ë¡œë“œ
```python
# ì—¬ëŸ¬ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë¡œë“œ
for k in range(2, 11):  # 2~10 í´ëŸ¬ìŠ¤í„° ìˆ˜
    clusters = pd.read_csv(f'{path}/analysis/clustering/.../clusters.csv')
    adata.obs[f'kmeans{k}_clusters'] = list(clusters['Cluster'].astype(str))

# ê·¸ë˜í”„ í´ëŸ¬ìŠ¤í„°ë§
graph_clusters = pd.read_csv(path+'/analysis/clustering/.../clusters.csv')
adata.obs['graph_clusters'] = list(graph_clusters['Cluster'].astype(str))
```

**í´ëŸ¬ìŠ¤í„°ë§ ì¢…ë¥˜**:
- `graph_clusters`: Leiden ì•Œê³ ë¦¬ì¦˜ (ê·¸ë˜í”„ ê¸°ë°˜)
- `kmeans2_clusters` ~ `kmeans10_clusters`: K-means (ì—¬ëŸ¬ kê°’)

**ì¶œë ¥ AnnData êµ¬ì¡°**:
```python
# ì €ì¥ëœ AnnData íŒŒì¼ êµ¬ì¡°
# file: {tag}.h5ad

adata.shape = (10000, 300)  # 10,000 ì„¸í¬, 300 ìœ ì „ì
adata.X = ì¹´ìš´íŠ¸ í–‰ë ¬ (10000 Ã— 300)

adata.obs = ì„¸í¬ ë©”íƒ€ë°ì´í„° (10000 rows)
  columns: [cell_id, x_centroid, y_centroid, area,
            kmeans2_clusters, ..., kmeans10_clusters,
            graph_clusters]

adata.var = ìœ ì „ì ë©”íƒ€ë°ì´í„° (300 rows)
  columns: [gene_id, reason_of_inclusion, Annotation,
            Ensembl ID, in_panel]

adata.obsm['spatial'] = (10000, 2) ê³µê°„ ì¢Œí‘œ
adata.obsm['X_umap'] = (10000, 2) UMAP ê²°ê³¼
adata.obsm['X_pca'] = (10000, 10) PCA ê²°ê³¼
adata.obsm['X_tsne'] = (10000, 2) t-SNE ê²°ê³¼

adata.uns['spatial'] = ì´ë¯¸ì§€ ë° ìŠ¤ì¼€ì¼ ì •ë³´
adata.uns['spots'] = ë¦¬ë“œ ë ˆë²¨ ì •ë³´ DataFrame
```

---

#### í•¨ìˆ˜ 2: `format_xenium_adata_2023(path, tag, output_path)`

**ì°¨ì´ì ** (2022 ë²„ì „ê³¼ì˜ ì£¼ìš” ë³€ê²½ì‚¬í•­):

**Panel ì •ë³´ í˜•ì‹ ë³€í™”**:
```python
# 2022 ë²„ì „: panel.tsv íŒŒì¼
panel_info = pd.read_csv(path+'/panel.tsv', sep='\t')
# ê°„ë‹¨í•œ TSV í˜•ì‹

# 2023 ë²„ì „: gene_panel.json íŒŒì¼
f = open(path+'/gene_panel.json')
data = json.load(f)

# JSON íŒŒì‹± - ë” ë³µì¡í•œ êµ¬ì¡°
for r in range(len(data['payload']['targets'])):
    gene_name = data['payload']['targets'][r]['type']['data']['name']
    gene_id = data['payload']['targets'][r]['type']['data']['id']
    descriptor = data['payload']['targets'][r]['type']['descriptor']

    genes.append(gene_name)
    ids.append(gene_id)
    descriptors.append(descriptor)

f.close()

# ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
dict_inpanel = dict(zip(genes, descriptors))
dict_ENSEMBL = dict(zip(genes, ids))

adata.var['Ensembl ID'] = adata.var['gene_id'].map(dict_ENSEMBL)
adata.var['in_panel'] = adata.var['gene_id'].map(dict_inpanel)
```

**êµ¬ì¡° ë³€í™”**:
- Panel ì •ë³´ í˜•ì‹: TSV â†’ JSON (ë” ë³µì¡í•œ ë©”íƒ€ë°ì´í„° í¬í•¨)
- ìœ ì „ì ID í˜•ì‹ ë³€ê²½ (ìƒˆë¡œìš´ ID ìŠ¤í‚´)
- ì£¼ì„ í•„ë“œ ì¶”ê°€ (descriptor ì •ë³´)

---

#### í•¨ìˆ˜ 3: `format_xenium_adata_mid_2023(path, tag, output_path)`

**ìµœì‹  ë²„ì „ì˜ íŠ¹ì§•**:
```python
# ë” ë§ì€ ë©”íƒ€ë°ì´í„° í•„ë“œ ì§€ì›
# ê°œì„ ëœ ì¢Œí‘œê³„ ì²˜ë¦¬
# ìƒˆë¡œìš´ í’ˆì§ˆ ë©”íŠ¸ë¦­ í¬í•¨
# í•µ ê²½ê³„ ì •ë³´ (nucleus_boundaries.parquet)
# ì…€ ê²½ê³„ ì •ë³´ ì¶”ê°€ ì§€ì›
```

---

#### í•¨ìˆ˜ 4: `format_background(path)`

**ëª©ì **: ë°°ê²½ DAPI ì´ë¯¸ì§€ ì²˜ë¦¬ ë° í†µí•©

```python
def format_background(path):
    """
    ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ë‹¨ì¼ TIFFë¡œ í†µí•©
    """
    # 1ë‹¨ê³„: ì—¬ëŸ¬ ì´ë¯¸ì§€ íŒŒì¼ ê²€ìƒ‰
    # mosaic.tif, morphology_mip.ome.tif ë“±

    # 2ë‹¨ê³„: ì´ë¯¸ì§€ ë¡œë“œ
    img_list = []
    for file in image_files:
        img = tifffile.imread(file)
        img_list.append(img)

    # 3ë‹¨ê³„: í†µí•© (stitching) - ì´ë¯¸ì§€ ì¡°í•©
    stitched = stitch_images(img_list)
    # ì—¬ëŸ¬ íƒ€ì¼ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ë¡œ ì—°ê²°

    # 4ë‹¨ê³„: TIFFë¡œ ì €ì¥
    tifffile.imwrite(path + '/background.tiff', stitched)
    # ë°°ê²½ ì´ë¯¸ì§€ ì €ì¥
```

---

#### í•¨ìˆ˜ 5: `cell_area(adata)`

**ëª©ì **: ê° ì„¸í¬ì˜ ë©´ì  ê³„ì‚°

```python
def cell_area(adata):
    """
    Nucleus segmentationìœ¼ë¡œë¶€í„° ì„¸í¬ ë©´ì  ê³„ì‚°
    """
    # 1ë‹¨ê³„: nucleus_boundaries ë¡œë“œ
    boundaries = adata.obs['nucleus_boundary']  # polygon
    # ê° ì„¸í¬ì˜ ê²½ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë‹¤ê°í˜•

    # 2ë‹¨ê³„: ê° ê²½ê³„ì˜ ë©´ì  ê³„ì‚° (Shoelace formula)
    areas = []
    for boundary in boundaries:
        x, y = boundary[:, 0], boundary[:, 1]
        # Shoelace formula (ì‹ ë°œëˆ ê³µì‹)
        area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) -
                             np.dot(y, np.roll(x, 1)))
        areas.append(area)

    # 3ë‹¨ê³„: adataì— ì €ì¥
    adata.obs['nucleus_area'] = areas
```

**Shoelace Formula ì„¤ëª…**:
```
ë‹¤ê°í˜• ë„“ì´ = 0.5 * |Î£(x_i * y_(i+1) - x_(i+1) * y_i)|

ì˜ˆ: ì§ì‚¬ê°í˜• (0,0), (4,0), (4,3), (0,3)
    ë„“ì´ = 0.5 * |0*0 - 4*0 + 4*3 - 4*0 + 4*3 - 0*3 + 0*0 - 0*3|
        = 0.5 * |12 + 12| = 12
```

---

### ğŸ“„ xb/_quality_metrics.py (7KB) - í’ˆì§ˆ ì§€í‘œ ê³„ì‚°

**íŒŒì¼ êµ¬ì¡°**:
```python
_quality_metrics.py
â”œâ”€â”€ cell_density()                    â† ì„¸í¬ ë°€ë„
â”œâ”€â”€ proportion_of_assigned_reads()   â† ë¦¬ë“œ í• ë‹¹ë¥ 
â”œâ”€â”€ median_reads_cells()              â† ì¤‘ì•™ê°’ ë¦¬ë“œ/ì„¸í¬
â”œâ”€â”€ mean_reads_cells()                â† í‰ê·  ë¦¬ë“œ/ì„¸í¬
â”œâ”€â”€ percentile_5th_reads_cells()     â† 5ë°±ë¶„ìœ„ ë¦¬ë“œ/ì„¸í¬
â”œâ”€â”€ percentile_95th_reads_cells()    â† 95ë°±ë¶„ìœ„ ë¦¬ë“œ/ì„¸í¬
â”œâ”€â”€ number_of_cells()                 â† ì„¸í¬ ìˆ˜
â”œâ”€â”€ number_of_genes()                 â† ìœ ì „ì ìˆ˜
â”œâ”€â”€ median_genes_cells()              â† ì¤‘ì•™ê°’ ìœ ì „ì/ì„¸í¬
â”œâ”€â”€ mean_genes_cells()                â† í‰ê·  ìœ ì „ì/ì„¸í¬
â”œâ”€â”€ percentile_5th_genes_cells()     â† 5ë°±ë¶„ìœ„ ìœ ì „ì/ì„¸í¬
â””â”€â”€ percentile_95th_genes_cells()    â† 95ë°±ë¶„ìœ„ ìœ ì „ì/ì„¸í¬
```

#### í•¨ìˆ˜ 1: `proportion_of_assigned_reads(adata_sp)`

```python
def proportion_of_assigned_reads(adata_sp):
    """
    ë¦¬ë“œ í• ë‹¹ íš¨ìœ¨ ê³„ì‚°

    ì˜ë¯¸: ì„¸í¬ì— í• ë‹¹ëœ ë¦¬ë“œ ìˆ˜ / ì „ì²´ ë””ì½”ë”©ëœ ë¦¬ë“œ ìˆ˜
          â†’ ì„¸ê·¸ë¨¼í…Œì´ì…˜ í’ˆì§ˆ ì§€í‘œ
    """
    # 1ë‹¨ê³„: ê° ì„¸í¬ì˜ ë¦¬ë“œ í•©ì‚°
    assigned_reads = np.sum(adata_sp.layers['raw'])
    # ì˜ˆ: 1,234,567 reads

    # 2ë‹¨ê³„: ì „ì²´ ë¦¬ë“œ ìˆ˜ (including background)
    total_reads = adata_sp.uns['spots'].shape[0]
    # ì˜ˆ: 1,500,000 reads

    # 3ë‹¨ê³„: ë¹„ìœ¨ ê³„ì‚°
    proportion = assigned_reads / total_reads
    # ì˜ˆ: 0.822 (82.2% í• ë‹¹ë¥ )

    return proportion
```

**í•´ì„**:
```
0.9 ì´ìƒ: ìš°ìˆ˜í•œ ì„¸ê·¸ë¨¼í…Œì´ì…˜
0.7~0.9: ë³´í†µ
< 0.7: ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë¬¸ì œ ìˆìŒ
```

---

#### í•¨ìˆ˜ 2: `median_reads_cells(adata_sp)`

```python
def median_reads_cells(adata_sp):
    """
    ê° ì„¸í¬ë‹¹ ë¦¬ë“œ ìˆ˜ì˜ ì¤‘ì•™ê°’

    ì˜ë¯¸: ì „í˜•ì ì¸ ì„¸í¬ê°€ ê°–ëŠ” ë¦¬ë“œ ìˆ˜
    """
    # 1ë‹¨ê³„: ê° ì„¸í¬ì˜ ë¦¬ë“œ ìˆ˜ í•©ì‚°
    reads_per_cell = np.sum(adata_sp.layers['raw'], axis=1)
    # ê²°ê³¼: ë°°ì—´ [150, 320, 280, ..., 410]  (ê° ì„¸í¬ë³„ ë¦¬ë“œ ìˆ˜)

    # 2ë‹¨ê³„: ì¤‘ì•™ê°’ ê³„ì‚°
    median = np.median(reads_per_cell)
    # ì˜ˆ: 287 reads/cell

    return median
```

**ë¶„í¬ í•´ì„**:
```
Xenium ì¼ë°˜ì  ê°’:
- ë§ˆìš°ìŠ¤ ë‡Œ: 200~400 reads/cell
- ì¸ê°„ ë‡Œ: 150~350 reads/cell
- ìœ ë°©: 100~300 reads/cell

ë‚®ì€ ê°’ (<100):
  - ë¦¬ë“œ ê¹Šì´ ë¶€ì¡±
  - ì„¸ê·¸ë¨¼í…Œì´ì…˜ ì˜¤ë¥˜
  - ì¡°ì§ ì†ìƒ
```

---

#### í•¨ìˆ˜ 3: `cell_density(adata_sp)`

```python
def cell_density(adata_sp):
    """
    Convex hullì„ ì´ìš©í•œ ì„¸í¬ ë°€ë„ ê³„ì‚°

    ì˜ë¯¸: ì´ë¯¸ì§• ì˜ì—­ ë‚´ ë‹¨ìœ„ ë©´ì ë‹¹ ì„¸í¬ ìˆ˜
    """
    # 1ë‹¨ê³„: Convex hull ê³„ì‚° (ìµœì†Œ ê²½ê³„ ë‹¤ê°í˜•)
    coordinates = np.array(adata_sp.uns['spots'].loc[:, ['x', 'y']])
    # ê²°ê³¼: (n_reads, 2) ë°°ì—´

    hull = ConvexHull(coordinates)
    # ConvexHull ê°ì²´ ìƒì„±

    # 2ë‹¨ê³„: ê²½ê³„ ì˜ì—­ ë©´ì  ê³„ì‚°
    area = hull.area  # Î¼mÂ²
    # ì˜ˆ: 50,000 Î¼mÂ²

    # 3ë‹¨ê³„: ë°€ë„ ê³„ì‚°
    density = adata_sp.shape[0] / area
    # ì˜ˆ: 5000 cells / 50000 Î¼mÂ² = 0.1 cells/Î¼mÂ²

    return density
```

**ë°€ë„ í•´ì„**:
```
ì¡°ì§ë³„ ì¼ë°˜ì  ë°€ë„:
- ë‡Œ: 0.05~0.15 cells/Î¼mÂ²
- ìœ ë°©: 0.1~0.3 cells/Î¼mÂ²
- í: 0.02~0.1 cells/Î¼mÂ²

ë†’ì€ ë°€ë„: ì„¸í¬ í˜¼ì¡ â†’ ì„¸ê·¸ë¨¼í…Œì´ì…˜ ì–´ë ¤ì›€
ë‚®ì€ ë°€ë„: ì„¸í¬ í¬ì†Œ â†’ ë¶„ì„ ì–´ë ¤ì›€
```

---

#### í•¨ìˆ˜ 4: `percentile_5th_genes_cells()` ë° `percentile_95th_genes_cells()`

```python
def percentile_5th_genes_cells(adata_sp):
    """
    ìœ ì „ì/ì„¸í¬ ìˆ˜ì˜ 5ë°±ë¶„ìœ„

    ì˜ë¯¸: í•˜ìœ„ 5%ì˜ ì„¸í¬ë“¤ì´ ê°€ì§„ ìœ ì „ì ìˆ˜
          (ì €í’ˆì§ˆ ì„¸í¬ ì‹ë³„)
    """
    # 1ë‹¨ê³„: ê° ì„¸í¬ì˜ ìœ ì „ì ìˆ˜ ê³„ì‚°
    genes_per_cell = np.sum((adata_sp.layers['raw'] > 0) * 1, axis=1)
    # ë…¼ë¦¬: 0ì´ ì•„ë‹Œ ìœ ì „ì ê°œìˆ˜ = ê°ì§€ëœ ìœ ì „ì
    # ì˜ˆ: [45, 67, 82, ..., 120]

    # 2ë‹¨ê³„: 5ë°±ë¶„ìœ„ ê³„ì‚°
    p5 = np.percentile(genes_per_cell, 5)
    # ì˜ˆ: 28 genes/cell

    return p5
```

**í’ˆì§ˆ í‰ê°€**:
```
ì¼ë°˜ì  ê¸°ì¤€:
- 5ë°±ë¶„ìœ„ > 20 genes: ì¢‹ìŒ
- 5~20 genes: ì¤‘ê°„
- < 5 genes: ì €í’ˆì§ˆ

95ë°±ë¶„ìœ„:
- > 200 genes: ìš°ìˆ˜í•œ ê¹Šì´
- 100~200: ë³´í†µ
- < 100: ì œí•œì 
```

---

### ğŸ“„ xb/_combined.py (1.4KB) - í†µí•© í’ˆì§ˆ í‰ê°€

```python
def all_quality_metrics(adata_sp):
    """
    ëª¨ë“  í’ˆì§ˆ ì§€í‘œë¥¼ í•œ ë²ˆì— ê³„ì‚°
    """
    results = {
        'proportion_assigned': proportion_of_assigned_reads(adata_sp),
        'n_cells': number_of_cells(adata_sp),
        'n_genes': number_of_genes(adata_sp),
        'median_reads_cell': median_reads_cells(adata_sp),
        'mean_reads_cell': mean_reads_cells(adata_sp),
        'p5_reads_cell': percentile_5th_reads_cells(adata_sp),
        'p95_reads_cell': percentile_95th_reads_cells(adata_sp),
        'median_genes_cell': median_genes_cells(adata_sp),
        'mean_genes_cell': mean_genes_cells(adata_sp),
        'p5_genes_cell': percentile_5th_genes_cells(adata_sp),
        'p95_genes_cell': percentile_95th_genes_cells(adata_sp),
        'cell_density': cell_density(adata_sp),
    }

    return pd.DataFrame([results])
```

**ë°˜í™˜ ê°’ ì˜ˆì‹œ**:
```
              proportion_assigned  n_cells  n_genes  median_reads_cell  mean_reads_cell
0                          0.822    10000      300              287.5            298.3
```

---

## SECTION 2: 5_segmentation_benchmark ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬

### ğŸ“„ 5_segmentation_benchmark/methods.py (18KB)

**íŒŒì¼ ëª©ì **: ë‹¤ì–‘í•œ ì„¸ê·¸ë¨¼í…Œì´ì…˜ ì•Œê³ ë¦¬ì¦˜ì„ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ë¡œ ì œê³µ

#### í•¨ìˆ˜ 1: `segment_nuclei(img, layer=None, library_id=None, method='watershed', ...)`

```python
def segment_nuclei(
    img: ImageContainer,
    layer: Optional[str] = None,
    method: str = "watershed",
    channel: Optional[int] = 0,
    **kwargs
) -> Optional[ImageContainer]:
    """
    Squidpy ê¸°ë°˜ í•µ ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë˜í¼

    Parameters:
    -----------
    img : ImageContainer (squidpy)
        ê³ í•´ìƒë„ ì´ë¯¸ì§€ (DAPI ì±„ë„)

    method : str
        - "watershed" : ë¶„ìˆ˜ë ¹ ì•Œê³ ë¦¬ì¦˜ (ë¹ ë¦„, ê¸°ë³¸ê°’)
        - ë˜ëŠ” ì»¤ìŠ¤í…€ í•¨ìˆ˜

    channel : int
        ì‚¬ìš©í•  ì±„ë„ ë²ˆí˜¸ (0=DAPI)

    Returns:
    --------
    ImageContainer
        'segmented_nucleus' ë ˆì´ì–´ì— ë¼ë²¨ë§ëœ ì´ë¯¸ì§€
    """

    # 1ë‹¨ê³„: ì„ íƒì  Gaussian ë¸”ëŸ¬
    if "blur_std" in kwargs and kwargs["blur_std"] > 0:
        sq.im.process(
            img,
            layer="image",
            method="smooth",
            sigma=kwargs["blur_std"],
            truncate=4.0,
            layer_added="image"
        )
        del kwargs["blur_std"]

    # 2ë‹¨ê³„: Squidpy ì„¸ê·¸ë¨¼í…Œì´ì…˜ í˜¸ì¶œ
    return sq.im.segment(
        img=img,
        layer="image",
        library_id=library_id,
        method=method,
        channel=channel,
        **kwargs
    )
```

**ë‚´ë¶€ ì²˜ë¦¬ (Squidpy)**:
```
1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
   â†“
2. ê±°ë¦¬ ë³€í™˜ (distance transform)
   â†“
3. ê·¹ê°’ ì°¾ê¸° (local maxima)
   â†“
4. ë¶„ìˆ˜ë ¹ ì•Œê³ ë¦¬ì¦˜ ì ìš©
   â†“
5. ë¼ë²¨ ì˜ìƒ ë°˜í™˜ (ê° í•µë§ˆë‹¤ ê³ ìœ  ID)
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
ImageContainer.layers['segmented_nucleus']
=
[[ 0  0  0  1  1  1  0  0]
 [ 0  2  2  1  1  1  0  0]
 [ 2  2  2  0  0  1  0  0]
 [ 0  0  0  3  3  3  3  0]
 [ 4  4  4  3  3  3  3  5]
 [ 4  4  4  0  0  0  0  5]]

# 0 = ë°°ê²½, 1,2,3,4,5 = ê°ê°ì˜ í•µ ID
```

---

#### í•¨ìˆ˜ 2: `segment_cellpose(img, hyperparams=None)`

```python
def segment_cellpose(
    img: NDArrayA,
    hyperparams: Optional[dict] = None
) -> NDArrayA:
    """
    Cellpose ì‹ ê²½ë§ ê¸°ë°˜ ì„¸ê·¸ë¨¼í…Œì´ì…˜

    ì…ë ¥:
    -----
    img : numpy array
        2D/3D ì´ë¯¸ì§€ ë˜ëŠ” ì´ë¯¸ì§€ ë°°ì—´
        í˜•íƒœ: (height, width) ë˜ëŠ” (depth, height, width)

    hyperparams : dict
        ì„ íƒì  í•˜ì´í¼íŒŒë¼ë¯¸í„°
        ì˜ˆ: {'model_type': 'nuclei', 'diameter': 30, 'flow_threshold': 0.4}

    ë°˜í™˜:
    -----
    masks : numpy array
        ë¼ë²¨ë§ëœ ì´ë¯¸ì§€ (ê° í•µë§ˆë‹¤ ê³ ìœ  ë²ˆí˜¸)
    """

    from cellpose import models

    # 1ë‹¨ê³„: ëª¨ë¸ íƒ€ì… ì„ íƒ
    model_type = (hyperparams.get('model_type')
                  if hyperparams else 'nuclei')
    # ì„ íƒì§€: 'nuclei', 'cyto', 'cyto2'

    # 2ë‹¨ê³„: Cellpose ëª¨ë¸ ì´ˆê¸°í™”
    model = models.Cellpose(model_type=model_type)
    # ì‚¬ì „í•™ìŠµëœ ì‹ ê²½ë§ ë¡œë“œ

    # 3ë‹¨ê³„: í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¤€ë¹„
    params = {}
    if hyperparams and 'model_type' in hyperparams:
        del hyperparams['model_type']
    if hyperparams:
        params = hyperparams

    # 4ë‹¨ê³„: ì„¸ê·¸ë¨¼í…Œì´ì…˜ ì‹¤í–‰
    masks, flows, styles, diameters = model.eval(
        img,
        channels=[0, 0],  # DAPI ì±„ë„ë§Œ ì‚¬ìš©
        **params
    )
    # channels=[0,0] = ë¹¨ê°•/ì´ˆë¡ ì±„ë„ ì—†ìŒ, DAPIë§Œ

    return masks
```

**ë™ì‘ ì›ë¦¬** (ë‚´ë¶€):
```
ì´ë¯¸ì§€ â†’ Cellpose ì‹ ê²½ë§ â†’ Flows (ë²¡í„°ì¥) â†’ Masks (ë¼ë²¨)

1. ì‹ ê²½ë§ì´ ê° í”½ì…€ì˜ ì›€ì§ì„ ë²¡í„°(flow) ì˜ˆì¸¡
2. íë¦„ì„ ë”°ë¼ê°€ë©° ì„¸í¬ ê²½ê³„ ì¶”ì 
3. ê° ì„¸í¬ì— ê³ ìœ  ID í• ë‹¹
```

**í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
```python
params = {
    'diameter': 30,           # ì˜ˆìƒ í•µ ì§ê²½ (í”½ì…€)
    'flow_threshold': 0.4,    # íë¦„ ì‹ ë¢°ë„ ì„ê³„ê°’
    'cellprob_threshold': 0,  # ì„¸í¬ í™•ë¥  ì„ê³„ê°’
    'min_size': 15,           # ìµœì†Œ ì„¸í¬ í¬ê¸°
    'batch_size': 8,          # GPU ë°°ì¹˜ í¬ê¸°
}
```

---

#### í•¨ìˆ˜ 3: `segment_binning(img, bin_size)`

```python
def segment_binning(
    img: NDArrayA,
    bin_size: int
) -> NDArrayA:
    """
    ê·¸ë¦¬ë“œ ê¸°ë°˜ ë°”ì´ë‹ (ê°€ì¥ ë¹ ë¥¸ ë°©ë²•)

    ì›ë¦¬: ì´ë¯¸ì§€ë¥¼ bin_sizeÃ—bin_size ê²©ìë¡œ ë‚˜ëˆ”
          ê° ê²©ì ì…€ì´ í•˜ë‚˜ì˜ "ì„¸í¬"

    ì…ë ¥:
    -----
    img : array
        2D ì´ë¯¸ì§€ (DAPI)

    bin_size : int
        ê²©ì í¬ê¸° (í”½ì…€)
        ì˜ˆ: bin_size=10 â†’ 10Ã—10 í”½ì…€ ë¸”ë¡

    ë°˜í™˜:
    -----
    bins : array
        ê° í”½ì…€ì— í• ë‹¹ëœ bin ID
    """

    # 1ë‹¨ê³„: ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
    n = np.shape(img)[0]  # ë†’ì´
    m = np.shape(img)[1]  # ë„ˆë¹„
    # ì˜ˆ: img.shape = (2048, 2048)

    # 2ë‹¨ê³„: ê·¸ë¦¬ë“œ ì¢Œí‘œ ìƒì„±
    x = np.floor(np.mgrid[0:n, 0:m][0] / bin_size)
    y = np.floor(np.mgrid[0:n, 0:m][1] / bin_size)

    # 3ë‹¨ê³„: 2D ì¢Œí‘œë¥¼ 1D bin IDë¡œ ë³€í™˜
    n_bins_y = np.ceil(m / bin_size)
    bins = x * n_bins_y + y + 1
    # ì„ í˜• ì¸ë±ì‹±: (row, col) â†’ unique_id

    return bins
```

**ì‹œê°í™”**:
```
bin_size=10ì¸ ê²½ìš°
[[1  1  1  1  1  1  1  1  1  1  2  2  2 ...
 [1  1  1  1  1  1  1  1  1  1  2  2  2 ...
 [1  1  1  1  1  1  1  1  1  1  2  2  2 ...
 ...
 [10 10 10 10 10 10 ... 20 20 20 ... ]
```

**íŠ¹ì§•**:
- ì¥ì : ë§¤ìš° ë¹ ë¦„ (O(n) ë³µì¡ë„)
- ë‹¨ì : ì‹¤ì œ ì„¸í¬ ê²½ê³„ ë¬´ì‹œ, ì •ë³´ ì†ì‹¤

---

### ğŸ“„ 5_segmentation_benchmark/metrics.py (20KB)

**íŒŒì¼ ëª©ì **: ì„¸ê·¸ë¨¼í…Œì´ì…˜ í’ˆì§ˆ í‰ê°€ ì§€í‘œ

#### í•¨ìˆ˜ 1: `proportion_of_assigned_reads(adata, segmentation)`

```python
def proportion_of_assigned_reads(adata_sp, pipeline_output=True):
    """
    ì„¸ê·¸ë¨¼í…Œì´ì…˜ í’ˆì§ˆ ì§€í‘œ: ë¦¬ë“œ í• ë‹¹ íš¨ìœ¨

    ë¡œì§:
    -----
    1. ëª¨ë“  ë¦¬ë“œë¥¼ ì„¸ê·¸ë¨¼í…Œì´ì…˜ìœ¼ë¡œë¶€í„° ì–´ëŠ "ì„¸í¬"ì— í• ë‹¹í–ˆë‚˜?
    2. í• ë‹¹ëœ ë¦¬ë“œ / ì „ì²´ ë¦¬ë“œ = íš¨ìœ¨

    ì˜ë¯¸: ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ì„¸ê·¸ë¨¼í…Œì´ì…˜
    """

    # í• ë‹¹ëœ ë¦¬ë“œ í•©ì‚°
    assigned_reads = np.sum(adata_sp.layers['raw'])
    # adata.layers['raw'] = ì„¸í¬Ã—ìœ ì „ì ì¹´ìš´íŠ¸ í–‰ë ¬
    # ì˜ˆ: [[5, 3, 0, ...],
    #      [2, 0, 4, ...],
    #      [10, 8, 1, ...]]
    # np.sum ê²°ê³¼: ëª¨ë“  ì›ì†Œì˜ í•©

    # ì „ì²´ ë¦¬ë“œ ìˆ˜
    total_reads = adata_sp.uns['spots'].shape[0]
    # adata.uns['spots'] = ëª¨ë“  ë¦¬ë“œ ì •ë³´ (transcript ë ˆë²¨)

    # ë¹„ìœ¨ ê³„ì‚°
    proportion = assigned_reads / total_reads
    # ì˜ˆ: 1,000,000 / 1,200,000 = 0.833

    return proportion
```

**í•´ì„**:
```
Cellpose: 0.85~0.95  (ë§¤ìš° ì •í™•)
Watershed: 0.75~0.88  (ì¤‘ê°„ ìˆ˜ì¤€)
Baysor: 0.88~0.96    (ìš°ìˆ˜)
Binning: 0.65~0.80   (ë¹ ë¥´ì§€ë§Œ ëœ ì •í™•)
```

---

#### í•¨ìˆ˜ 2: `rand_idx(assignments)`

```python
def rand_idx(assignments):
    """
    ì„œë¡œ ë‹¤ë¥¸ ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë°©ë²•ì˜ ì¼ì¹˜ë„ ê³„ì‚°

    ì…ë ¥:
    -----
    assignments : pd.DataFrame
        í–‰: ê° ë¦¬ë“œ
        ì—´: ê° ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë°©ë²•ì˜ ê²°ê³¼
        ê°’: í• ë‹¹ëœ ì„¸í¬ ID

        ì˜ˆ:
        |   | Cellpose | Watershed | Baysor |
        |---|----------|-----------|--------|
        | 0 |    1     |     1     |   1    |
        | 1 |    2     |     2     |   2    |
        | 2 |    1     |     3     |   1    |
        | 3 |    3     |     2     |   5    |

    ë°˜í™˜:
    ------
    ARI í–‰ë ¬ : pd.DataFrame
        ê° ë°©ë²• ìŒì˜ Adjusted Rand Index

        |           | Cellpose | Watershed | Baysor |
        |-----------|----------|-----------|--------|
        | Cellpose  |   1.00   |   0.72    |  0.88  |
        | Watershed |   0.72   |   1.00    |  0.65  |
        | Baysor    |   0.88   |   0.65    |  1.00  |
    """

    # ARI í–‰ë ¬ ì´ˆê¸°í™”
    rand_matrix = np.zeros([len(assignments.columns),
                            len(assignments.columns)])

    # ëª¨ë“  ë°©ë²• ìŒì— ëŒ€í•´ ê³„ì‚°
    for i in range(len(assignments.columns)):
        for j in range(len(assignments.columns)):
            # ië²ˆì§¸ ë°©ë²•ê³¼ jë²ˆì§¸ ë°©ë²•ì˜ í• ë‹¹ ë¹„êµ
            c1 = assignments.iloc[:, i]  # ë°©ë²• iì˜ í• ë‹¹
            c2 = assignments.iloc[:, j]  # ë°©ë²• jì˜ í• ë‹¹

            # Adjusted Rand Index ê³„ì‚°
            ari = sklearn.metrics.adjusted_rand_score(c1, c2)
            # ARI = (Rand Index - expected) / (max - expected)
            # ë²”ìœ„: -1 ~ 1
            #   1.0 = ì™„ë²½íˆ ì¼ì¹˜
            #   0.0 = ë¬´ì‘ìœ„ ì¼ì¹˜ ìˆ˜ì¤€
            #  -1.0 = ì™„ë²½íˆ ë°˜ëŒ€

            rand_matrix[i, j] = ari

    return pd.DataFrame(rand_matrix)
```

**í•´ì„**:
```
ARI > 0.8: ë§¤ìš° ìœ ì‚¬
ARI 0.5~0.8: ì¤‘ê°„ ìˆ˜ì¤€
ARI < 0.5: í° ì°¨ì´
```

---

## SECTION 3: ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬ ìœ í‹¸ë¦¬í‹°

### ğŸ“„ 5_segmentation_benchmark/gen_counts.py (15KB)

**íŒŒì¼ ëª©ì **: ì„¸ê·¸ë¨¼í…Œì´ì…˜ ê²°ê³¼ë¡œë¶€í„° ì¹´ìš´íŠ¸ í–‰ë ¬ ìƒì„±

#### ì£¼ìš” í•¨ìˆ˜ë“¤

```python
def main():
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸
    """

    # 1ë‹¨ê³„: ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser()
    parser.add_argument('-d', '--data', required=True,
                        help='Output directory with assignments_.csv')
    parser.add_argument('-s', '--singlecell', required=True,
                        help='Path to single cell anndata')
    parser.add_argument('-as', '--assignment', required=True,
                        help='Method name after assignments_')
    parser.add_argument('-id', '--id_code', required=True,
                        help='ID for saving results')
    parser.add_argument('-n', '--normalize', default='total',
                        help='Normalization method')
    # ... ê¸°íƒ€ ì¸ìë“¤

    args = parser.parse_args()

    # 2ë‹¨ê³„: scRNA-seq ì°¸ê³  ë°ì´í„° ë¡œë“œ
    adata_sc = sc.read(args.singlecell)
    # ì˜ˆ: 40,000 ì„¸í¬, 20,000 ìœ ì „ìì˜ ì°¸ê³  ë°ì´í„°

    # 3ë‹¨ê³„: í• ë‹¹ íŒŒì¼ë¡œë¶€í„° AnnData ìƒì„±
    adata = generate_adata(
        molecules=f'{args.data}/assignments_{args.assignment}.csv',
        prior_pct=0.7,
        ct_method='ssam',
        ct_certainty_threshold=0.7,
        adata_sc=adata_sc
    )
    # generate_adataëŠ” ë³„ë„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

    # 4ë‹¨ê³„: ì„¸í¬ ë©´ì  ì •ê·œí™” (ì„ íƒì )
    if args.normalize == 'area':
        # ì„¸í¬ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ì •ê·œí™”

        # ì˜ì—­ ì •ë³´ ì°¾ê¸°
        area_file = f'{args.data}/areas_{args.assignment}.csv'
        if os.path.exists(area_file):
            areas = pd.read_csv(area_file, header=None, index_col=0)
            adata.obs['area'] = areas[1][adata.obs['cell_id']].values

        # Alpha shapeë¡œ ì˜ì—­ ê³„ì‚° (ë” ì •ë°€)
        if args.hyperparams.get('alpha'):
            calculate_alpha_area(adata, alpha=args.hyperparams['alpha'])

        # ì •ê·œí™”
        normalize_by_area(adata)

    # 5ë‹¨ê³„: ê²°ê³¼ ì €ì¥
    output_file = (f"{args.data}/counts_{args.assignment}"
                   f"_{args.normalize}-{args.id_code}.h5ad")
    adata.write_h5ad(output_file)
    print(f"ì €ì¥ë¨: {output_file}")
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
ì›ë³¸:
  ì„¸í¬ 1: 5Î¼mÂ² ë©´ì , ì¹´ìš´íŠ¸ 500 â†’ ì •ê·œí™” í›„ 100 (per Î¼mÂ²)
  ì„¸í¬ 2: 20Î¼mÂ² ë©´ì , ì¹´ìš´íŠ¸ 1500 â†’ ì •ê·œí™” í›„ 75 (per Î¼mÂ²)

ì •ê·œí™” ì „ ë¬¸ì œ: í° ì„¸í¬ê°€ ë§ì€ ë¦¬ë“œë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì„
ì •ê·œí™” í›„ ì´ì : ì„¸í¬ í¬ê¸° íš¨ê³¼ ì œê±°, ìƒë¬¼í•™ì  ì‹ í˜¸ë§Œ ë‚¨ìŒ
```

---

### ğŸ“„ 5_segmentation_benchmark/util.py (8KB)

```python
def generate_adata(molecules, prior_pct, ct_method,
                   ct_certainty_threshold, adata_sc):
    """
    ë¦¬ë“œ-ì„¸í¬ í• ë‹¹ íŒŒì¼ë¡œë¶€í„° AnnData ìƒì„±

    ì…ë ¥:
    -----
    molecules : str
        CSV íŒŒì¼ ê²½ë¡œ
        columns: [read_id, x, y, gene, cell_id, ...]

        ì˜ˆ:
        | read_id | x     | y     | gene  | cell_id |
        |---------|-------|-------|-------|---------|
        | 0       | 100.2 | 200.5 | DAPI  | 1       |
        | 1       | 101.1 | 200.8 | GAD1  | 1       |
        | 2       | 150.3 | 300.2 | VIP   | 2       |
        | 3       | 102.5 | 201.1 | GABA  | 1       |

    ct_method : str
        ì„¸í¬ ìœ í˜• í• ë‹¹ ë°©ë²•
        - 'ssam' : Spatial Single-cell Assignment Method
        - 'majority' : ë‹¤ìˆ˜ íˆ¬í‘œ
        - 'pciSeq' : í™•ë¥  ê¸°ë°˜

    ct_certainty_threshold : float
        ì„¸í¬ ìœ í˜• í™•ì‹ ë„ ì„ê³„ê°’ (0~1)

    adata_sc : AnnData
        scRNA-seq ì°¸ê³  ë°ì´í„°

    ë°˜í™˜:
    ------
    adata : AnnData
        ì„¸í¬ Ã— ìœ ì „ì ì¹´ìš´íŠ¸ í–‰ë ¬
    """

    # 1ë‹¨ê³„: í• ë‹¹ íŒŒì¼ ì½ê¸°
    molecules_df = pd.read_csv(molecules)

    # 2ë‹¨ê³„: ì„¸í¬ë³„ ìœ ì „ì ì¹´ìš´íŠ¸ í–‰ë ¬ ìƒì„±
    # Pivot: (read_level) â†’ (cell_level)
    counts = molecules_df.pivot_table(
        index='cell_id',
        columns='gene',
        values='read_id',
        aggfunc='count',
        fill_value=0
    )

    # ì˜ˆì‹œ:
    #        DAPI  GAD1  VIP  GABA
    # cell_id
    # 1        3    2    1    2
    # 2        4    1    5    0
    # 3        5    3    2    1

    # 3ë‹¨ê³„: AnnData ìƒì„±
    adata = AnnData(counts)

    # 4ë‹¨ê³„: ì„¸í¬ ë©”íƒ€ë°ì´í„° ì¶”ê°€
    cell_coords = molecules_df.groupby('cell_id')[['x', 'y']].mean()
    adata.obsm['spatial'] = np.array(cell_coords)
    adata.obs['cell_id'] = counts.index

    # 5ë‹¨ê³„: ì„¸í¬ ìœ í˜• í• ë‹¹ (ì°¸ê³  ë°ì´í„° ì´ìš©)
    if ct_method == 'ssam':
        # SSAM: ê° ì„¸í¬ì˜ ìœ ì „ì í”„ë¡œí•„ì„ scRNA-seqê³¼ ë¹„êµ
        # ê°€ì¥ ìœ ì‚¬í•œ ì„¸í¬ ìœ í˜• í• ë‹¹

        for cell_id in adata.obs.index:
            cell_profile = adata[cell_id, :].X.flatten()

            # scRNA-seq ê° ì„¸í¬ ìœ í˜•ê³¼ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            correlations = {}
            for ct in adata_sc.obs['celltype'].unique():
                sc_cells = adata_sc[adata_sc.obs['celltype'] == ct]
                mean_profile = sc_cells.X.mean(axis=0).flatten()
                corr = np.corrcoef(cell_profile, mean_profile)[0, 1]
                correlations[ct] = corr

            # ê°€ì¥ ë†’ì€ ìƒê´€ê³„ìˆ˜ ì„ íƒ
            best_ct = max(correlations, key=correlations.get)
            best_corr = correlations[best_ct]

            # í™•ì‹ ë„ ì„ê³„ê°’ í™•ì¸
            if best_corr > ct_certainty_threshold:
                adata.obs.loc[cell_id, 'celltype'] = best_ct
                adata.obs.loc[cell_id, 'confidence'] = best_corr
            else:
                adata.obs.loc[cell_id, 'celltype'] = 'Uncertain'
                adata.obs.loc[cell_id, 'confidence'] = best_corr

    return adata


def normalize_by_area(adata):
    """
    ì„¸í¬ ë©´ì ìœ¼ë¡œ ì •ê·œí™”

    ë¡œì§:
    -----
    ì„¸í¬ê°€ í¬ë©´ ë” ë§ì€ ë¦¬ë“œë¥¼ í¬í•¨ ê°€ëŠ¥
    â†’ ë©´ì ìœ¼ë¡œ ë‚˜ëˆ„ì–´ "ë†ë„" í˜•íƒœë¡œ ë³€í™˜

    ì •ê·œí™” ì „:
    ì„¸í¬ 1 (10 Î¼mÂ²): 500 ì¹´ìš´íŠ¸
    ì„¸í¬ 2 (20 Î¼mÂ²): 900 ì¹´ìš´íŠ¸

    ì •ê·œí™” í›„:
    ì„¸í¬ 1: 500/10 = 50 (per Î¼mÂ²)
    ì„¸í¬ 2: 900/20 = 45 (per Î¼mÂ²)

    â†’ ì´ì œ ì„¸í¬ í¬ê¸° íš¨ê³¼ ì œê±°ë¨
    """

    if 'area' not in adata.obs:
        print("ê²½ê³ : 'area' ì •ë³´ ì—†ìŒ")
        return

    # ê° ì„¸í¬ì˜ ëª¨ë“  ìœ ì „ì ì¹´ìš´íŠ¸ë¥¼ ë©´ì ìœ¼ë¡œ ì •ê·œí™”
    for cell in adata.obs.index:
        area = adata.obs.loc[cell, 'area']
        adata[cell, :].X = adata[cell, :].X / area


def calculate_alpha_area(adata, alpha=0.1):
    """
    Alpha shapeë¥¼ ì´ìš©í•œ ì„¸í¬ ë©´ì  ê³„ì‚°

    Alpha shape: Convex hullì˜ ì¼ë°˜í™”
                 ì˜¤ëª©í•œ í˜•íƒœì˜ ê²½ê³„ë„ ê°ì§€ ê°€ëŠ¥
    """

    from alphashape import alphashape

    for cell_id in adata.obs.index:
        # ì´ ì„¸í¬ì˜ ëª¨ë“  ë¦¬ë“œ ì¢Œí‘œ
        molecules = adata.obs[adata.obs['cell_id'] == cell_id]
        coords = np.column_stack([molecules['x'], molecules['y']])

        # Alpha shape ê³„ì‚°
        alpha_shape = alphashape(coords, alpha)
        area = alpha_shape.area

        adata.obs.loc[cell_id, 'alpha_area'] = area
```

---

### ğŸ“„ 5_segmentation_benchmark/run_segmentation.py (25KB)

**íŒŒì¼ ëª©ì **: ëª¨ë“  ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë°©ë²•ì„ ìë™ìœ¼ë¡œ ì‹¤í–‰

```python
#!/usr/bin/env python

if __name__ == '__main__':
    """
    ì „ì²´ ë²¤ì¹˜ë§ˆí‚¹ íŒŒì´í”„ë¼ì¸ ìë™í™”
    """

    # 1ë‹¨ê³„: ì„¤ì • íŒŒì¼ ì½ê¸°
    config = load_config('config.yaml')

    # 2ë‹¨ê³„: ì…ë ¥ ë°ì´í„° ë¡œë“œ
    adata = sc.read_h5ad(config['input_path'])
    # ì˜ˆ: 10,000 ì„¸í¬, 300 ìœ ì „ì

    # 3ë‹¨ê³„: ì´ë¯¸ì§€ ë¡œë“œ
    img = sq.im.ImageContainer(config['image_path'])
    # DAPI ì´ë¯¸ì§€ ë¡œë“œ

    # 4ë‹¨ê³„: ê° ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë°©ë²• ì‹¤í–‰
    methods = ['nuclei', 'cellpose', 'watershed', 'baysor', 'binning']
    results = {}

    for method in methods:
        print(f"ì‹¤í–‰ ì¤‘: {method}...")

        # 4-1: ë°©ë²•ë³„ ì„¸ê·¸ë¨¼í…Œì´ì…˜
        if method == 'nuclei':
            seg = segment_nuclei(img, method='watershed')
        elif method == 'cellpose':
            seg = segment_cellpose(img.data, hyperparams={'diameter': 30})
        elif method == 'baysor':
            seg = run_baysor(adata, config_path='baysor_params.toml')
        elif method == 'binning':
            seg = segment_binning(img.data, bin_size=10)

        # 4-2: ì„¸ê·¸ë¨¼í…Œì´ì…˜ ê²°ê³¼ ì €ì¥
        results[method] = seg
        save_segmentation(seg, f'results/seg_{method}.tif')

        # 4-3: ì¹´ìš´íŠ¸ í–‰ë ¬ ìƒì„±
        adata_counts = generate_counts_from_seg(adata, seg)
        adata_counts.write_h5ad(f'results/counts_{method}.h5ad')

    # 5ë‹¨ê³„: í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
    metrics_table = pd.DataFrame()

    for method, seg in results.items():
        # ê° ë°©ë²•ì˜ ì„±ëŠ¥ í‰ê°€
        metrics = {
            'Method': method,
            'Read_Assignment': proportion_of_assigned_reads(...),
            'Mean_Reads_Cell': mean_reads_per_cell(...),
            'Mean_Genes_Cell': mean_genes_per_cell(...),
            'Runtime': measure_runtime(method),
            'Memory': measure_memory(method),
        }
        metrics_table = pd.concat([metrics_table, pd.DataFrame([metrics])])

    # 6ë‹¨ê³„: ê²°ê³¼ ë¹„êµ
    print(metrics_table.to_string())

    # 7ë‹¨ê³„: ì‹œê°í™”
    plot_comparison(metrics_table, output_file='results/comparison.pdf')
```

---

## ìš”ì•½

ì´ ë¬¸ì„œëŠ” Xenium Benchmarking í”„ë¡œì íŠ¸ì˜ í•µì‹¬ Python íŒŒì¼ë“¤ì˜ **ë‚´ë¶€ êµ¬ì¡°ì™€ í•¨ìˆ˜ë³„ ë™ì‘**ì„ ë§¤ìš° ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

### ì£¼ìš” í¬ì¸íŠ¸:

1. **formatting.py**: 3ê°€ì§€ ë²„ì „ì˜ Xenium í¬ë§·ì„ AnnDataë¡œ ë³€í™˜
   - 2022, early 2023, mid-2023+ ë²„ì „ ì§€ì›
   - ì••ì¶• í•´ì œ â†’ ë°ì´í„° ì½ê¸° â†’ AnnData ìƒì„± â†’ ê³µê°„/ë©”íƒ€ë°ì´í„° ì¶”ê°€

2. **_quality_metrics.py**: 12ê°€ì§€ í’ˆì§ˆ í‰ê°€ ì§€í‘œ
   - ë¦¬ë“œ ê´€ë ¨: í• ë‹¹ë¥ , ì¤‘ì•™ê°’, ë°±ë¶„ìœ„ìˆ˜
   - ìœ ì „ì ê´€ë ¨: ì„¸í¬ë‹¹ ìœ ì „ì ìˆ˜ í†µê³„
   - ê³µê°„ ê´€ë ¨: ì„¸í¬ ë°€ë„

3. **ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬**: 4ê°€ì§€ ë°©ë²• ë¹„êµ
   - Watershed (ë¹ ë¦„)
   - Cellpose (ì‹ ê²½ë§, ì •í™•)
   - Baysor (ìµœì í™” ê¸°ë°˜)
   - Binning (ì´ˆê³ ì†, ì •ë³´ ì†ì‹¤)

4. **ë©”íŠ¸ë¦­ ê³„ì‚°**: ì„¸ê·¸ë¨¼í…Œì´ì…˜ í’ˆì§ˆ í‰ê°€
   - ë¦¬ë“œ í• ë‹¹ íš¨ìœ¨
   - ë°©ë²• ê°„ ì¼ì¹˜ë„ (ARI)
   - í†µê³„ì  ë¹„êµ

---

## SECTION 4: ë…¼ë¬¸ì˜ ìµœì  ë¶„ì„ ì›Œí¬í”Œë¡œìš° (3ë‹¨ê³„ í†µí•© ê°€ì´ë“œ)

### ğŸ“‹ ê°œìš”

ì´ ì„¹ì…˜ì€ ë…¼ë¬¸ "Optimizing Xenium In Situ data utility by quality assessment and best practice analysis workflows"ì˜ **3ê°€ì§€ í•µì‹¬ ë‹¨ê³„**ë¥¼ í”„ë¡œì íŠ¸ì˜ ì‹¤ì œ ë…¸íŠ¸ë¶ê³¼ íŒŒì´ì¬ ì½”ë“œì™€ ë§¤ì¹­ì‹œí‚µë‹ˆë‹¤.

---

### ğŸ”· **1ë‹¨ê³„: ë°ì´í„° í¬ë§·íŒ… ë° ì´ˆê¸° íƒìƒ‰ (Data Loading & QC)**

**ë…¼ë¬¸ ì„¹ì…˜**: Figure 1, Extended Data Figure 1
**ê´€ë ¨ í´ë”**: `0_formatting/`, `1_datasets_exploration/`

#### 1-1: Xenium ì›ë³¸ ë°ì´í„° â†’ AnnData ë³€í™˜

**ë…¸íŠ¸ë¶**: `0_0_Formatting xenium to anndata.ipynb`
**íŒŒì´ì¬ ëª¨ë“ˆ**: `xb/formatting.py`

**ì‘ì—… íë¦„**:

```python
# Step 1: Xenium ê¸°ê³„ ì¶œë ¥ ë¡œë“œ
from xb.formatting import format_xenium_adata

adata = format_xenium_adata(
    path='/path/to/xenium_output/',
    tag='sample_001',
    output_path='/output/'
)

# ê²°ê³¼: adata.h5ad (ì™„ì „í•œ AnnData ê°ì²´)
# - X: (n_cells, n_genes) ì¹´ìš´íŠ¸ í–‰ë ¬
# - obsm['spatial']: (n_cells, 2) ê³µê°„ ì¢Œí‘œ
# - obs: ì„¸í¬ ë©”íƒ€ë°ì´í„°
# - var: ìœ ì „ì ë©”íƒ€ë°ì´í„°
# - uns['spots']: ë¦¬ë“œ ë ˆë²¨ ì •ë³´
```

**ì…/ì¶œë ¥**:
```
INPUT (Xenium ê¸°ê³„ ì¶œë ¥):
  â”œâ”€â”€ transcripts.csv.gz         (ëª¨ë“  ë¦¬ë“œ ì •ë³´)
  â”œâ”€â”€ cells.csv.gz               (ì„¸í¬ ì¢Œí‘œ, ë©´ì )
  â”œâ”€â”€ cell_feature_matrix/
  â”‚   â”œâ”€â”€ matrix.mtx.gz
  â”‚   â”œâ”€â”€ barcodes.tsv.gz
  â”‚   â””â”€â”€ features.tsv.gz
  â”œâ”€â”€ panel.tsv / gene_panel.json (ìœ ì „ì ì£¼ì„)
  â””â”€â”€ background.tiff            (DAPI ì´ë¯¸ì§€)

OUTPUT:
  adata.h5ad  (ì™„ì „ AnnData ê°ì²´)
```

**ì²˜ë¦¬ ë²„ì „** (ì„ íƒ):
- `format_xenium_adata()`: 2022 ë²„ì „
- `format_xenium_adata_2023()`: early 2023 ë²„ì „
- `format_xenium_adata_mid_2023()`: mid-2023+ ë²„ì „ (ê¶Œì¥)

---

#### 1-2: ê¸°ë³¸ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°

**ë…¸íŠ¸ë¶**: `1_1_Statistics_all_samples_using_txsim.ipynb`
**íŒŒì´ì¬ ëª¨ë“ˆ**: `xb/_quality_metrics.py`, `xb/_combined.py`

**ì‘ì—…**:

```python
from xb._combined import all_quality_metrics
import scanpy as sc

# í¬ë§·íŒ…ëœ ë°ì´í„° ë¡œë“œ
adata = sc.read_h5ad('sample_001.h5ad')

# ëª¨ë“  í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
quality_df = all_quality_metrics(adata)

# ì¶œë ¥:
#   proportion_assigned: 0.822  (82.2% ë¦¬ë“œ í• ë‹¹)
#   n_cells: 10420
#   n_genes: 540
#   median_reads_cell: 287
#   median_genes_cell: 198
#   p5_reads_cell: 45
#   p95_reads_cell: 612
#   cell_density: 0.085 cells/Î¼mÂ²
```

**ë…¼ë¬¸ ê¸°ì¤€** (Figure 1B):
```
âœ… í’ˆì§ˆ ì¢‹ìŒ:
  - proportion_assigned > 0.80
  - median_reads_cell > 200
  - median_genes_cell > 150
  - ê³ í’ˆì§ˆ ë¦¬ë“œ (QV > 20) > 81%

âš ï¸ í’ˆì§ˆ í™•ì¸ í•„ìš”:
  - proportion_assigned < 0.70
  - p5_genes_cell < 20
  - cell_density < 0.02 cells/Î¼mÂ²
```

**ì¶”ê°€ ë¶„ì„** (1_2~1_7 ë…¸íŠ¸ë¶):
- ì„¸í¬ ìœ í˜• ì‹ë³„
- ë¦¬ë“œ ë¶„ì‚° ë¶„ì„
- ë‹¤ì¤‘ì„¹ì…˜ í†µí•©
- êµ¬ì¡° íŠ¹ì„±í™” ì ìˆ˜ ê³„ì‚°

**ì¶œë ¥**:
```
figures/1.quality_assessment/
  â”œâ”€â”€ statistics_summary.csv
  â”œâ”€â”€ read_qv_distribution.pdf
  â”œâ”€â”€ reads_per_cell_distribution.pdf
  â”œâ”€â”€ genes_per_cell_distribution.pdf
  â””â”€â”€ cell_type_annotations.h5ad
```

---

### ğŸ”¶ **2ë‹¨ê³„: ìµœì  ì„¸í¬ ë¶„í•  (Cell Segmentation & Assignment)**

**ë…¼ë¬¸ ì„¹ì…˜**: Figure 3, Extended Data Figure 5
**ê´€ë ¨ í´ë”**: `5_segmentation_benchmark/`, `4_optimal_expansion/`

#### 2-1: ìµœì  í•µ í™•ì¥ ê±°ë¦¬ ê²°ì •

**ë…¸íŠ¸ë¶**: `4_1_Optimal_expansion_multisection.ipynb`

**ëª©í‘œ**: 15Âµm ê¸°ë³¸ í™•ì¥ì´ ì‹ í˜¸ ì˜¤ì—¼(bleeding)ì„ ì¼ìœ¼í‚¤ë¯€ë¡œ, ìµœì ê°’ ì°¾ê¸°

**í”„ë¡œì„¸ìŠ¤**:

```python
import scanpy as sc
from xb.methods import segment_cellpose
import numpy as np

# Step 1: ê³ í’ˆì§ˆ ì„¸ê·¸ë¨¼í…Œì´ì…˜ ê¸°ì¤€ ì¤€ë¹„
adata = sc.read_h5ad('sample.h5ad')
nuclei_seg = adata.obs['nucleus_segmentation']  # ì°¸ì¡°ìš©

# Step 2: í™•ì¥ ê±°ë¦¬ í…ŒìŠ¤íŠ¸
expansion_distances = [5, 7.5, 10, 12.5, 15, 17.5, 20]  # Î¼m

results = {}
for expansion in expansion_distances:
    # í•µ ì„¸ê·¸ë¨¼í…Œì´ì…˜ì„ í™•ì¥
    expanded_seg = expand_nuclei(nuclei_seg, expansion)

    # ë¦¬ë“œ í• ë‹¹ í‰ê°€
    iou = calculate_iou(
        expanded_seg,
        reference_segmentation  # Cellpose ë˜ëŠ” ìˆ˜ë™ ì£¼ì„
    )
    efficiency = proportion_of_assigned_reads(adata, expanded_seg)

    results[expansion] = {'IoU': iou, 'Efficiency': efficiency}

# Step 3: ìµœì ê°’ ì„ íƒ (ë…¼ë¬¸ ê²°ê³¼)
# ìµœì  í™•ì¥: 10-12.5 Âµm (ì¡°ì§ì— ë”°ë¼ ë‹¤ë¦„)
```

**ë…¼ë¬¸ ê¶Œì¥ê°’** (Methods - Optimal expansion):
```
ë§ˆìš°ìŠ¤ ë‡Œ:      10 Âµm
ì¸ê°„ ë‡Œ:        12.5 Âµm
ìœ ë°©ì•”:         10 Âµm
í:            7.5 Âµm (ì‘ì€ ì„¸í¬)
```

**ì¶œë ¥**:
```
figures/4.optimal_expansion/
  â”œâ”€â”€ iou_vs_expansion_distance.pdf
  â”œâ”€â”€ efficiency_vs_expansion_distance.pdf
  â”œâ”€â”€ optimal_expansion_value_table.csv
  â””â”€â”€ multi_section_consensus.pdf
```

---

#### 2-2: Cellpose + Baysor ì„¸ê·¸ë¨¼í…Œì´ì…˜

**ë…¸íŠ¸ë¶**: `5_1_Compare_Clustering on_different_segmentations.ipynb`
**íŒŒì´ì¬ ëª¨ë“ˆ**: `notebooks/5_segmentation_benchmark/methods.py`

**ë…¼ë¬¸ ê¶Œì¥ ì„¤ì •** (Methods - Segmentation):
```
ì•Œê³ ë¦¬ì¦˜: Cellpose v2.2.3 + Baysor v0.6.2
íŒŒì´í”„ë¼ì¸:
  1. Cellpose (v2.2.3)
     - ëª¨ë¸: 'nuclei' (CPn)
     - ì…ë ¥: DAPI ì´ë¯¸ì§€
     - ì§ê²½: auto ë˜ëŠ” 20-40 (ì¡°ì§ë³„)
     - ì¶œë ¥: nucleus_mask.tif

  2. Baysor (v0.6.2)
     - Prior Segmentation: nucleus_mask.tif
     - Prior Confidence: 0.8 (â˜… í•µì‹¬ íŒŒë¼ë¯¸í„°!)
       â†’ í•µ ë‚´ë¶€ ë¦¬ë“œì˜ ì •ì²´ì„±ì„ 80% ì‹ ë¢°
       â†’ ë‚˜ë¨¸ì§€ 20%ëŠ” ì£¼ë³€ ë°€ë„ & ìœ ì „ìë¡œ íŒë‹¨
     - ì¶œë ¥: cell_segmentation.json
```

**Baysor íŒŒë¼ë¯¸í„° ìƒì„¸**:

```python
# baysor_params.toml
[segmentation]
prior_segmentation = "nucleus_mask.tif"
prior_confidence = 0.8      # â˜…â˜…â˜… ê°€ì¥ ì¤‘ìš”

scale = 30.0                # ê³µê°„ ìŠ¤ì¼€ì¼ (Î¼m)
min_spots_per_cell = 3
max_iters = 500

[output]
save_polygons = true
save_masks = true
```

**ì‹¤í–‰ ì˜ˆì‹œ**:

```bash
# Cellpose ì‹¤í–‰
python -c "
from cellpose import models
import skimage.io as io

img = io.imread('dapi.tif')
model = models.Cellpose(model_type='nuclei')
masks, _, _, _ = model.eval(img, channels=[0, 0])
io.imsave('nucleus_mask.tif', masks)
"

# Baysor ì‹¤í–‰
baysor run \
    -o output_dir \
    -s nucleus_mask.tif \
    -p 0.8 \
    transcripts.csv
```

**í‰ê°€ ì§€í‘œ** (Extended Data Figure 5c):

```python
from xb.metrics import negative_marker_purity_reads

# NMP (Negative Marker Purity) ê³„ì‚°
nmp_score = negative_marker_purity_reads(
    adata_spatial,
    adata_reference,
    key='celltype'
)

# ë…¼ë¬¸ ê²°ê³¼:
# - Cellpose + Baysor (P=0.8): NMP = 0.92 â˜… ìµœê³ 
# - Cellpose + Baysor (P=0.5): NMP = 0.88
# - Cellpose + Baysor (P=0.2): NMP = 0.85
# - Cellposeë§Œ: NMP = 0.78
```

**ë¹„êµ ê²°ê³¼** (Figure 3c):
```
Cellpose + Baysor (P=0.8)ì˜ ì¥ì :
  âœ… ëª…í™•í•œ ì„¸í¬ ê²½ê³„
  âœ… ì‹ í˜¸ ì˜¤ì—¼ ìµœì†Œí™”
  âœ… ì„¸í¬ í¬ê¸° ì •í™•ë„ > 95%
  âœ… ë¦¬ë“œ í• ë‹¹ íš¨ìœ¨ > 85%
```

**ì¶œë ¥**:
```
figures/5.segmentation/
  â”œâ”€â”€ cellpose_nucleus_mask.tif
  â”œâ”€â”€ baysor_cell_segmentation.json
  â”œâ”€â”€ cell_boundaries_visualization.png
  â”œâ”€â”€ nmp_score_comparison.pdf
  â””â”€â”€ assignments_baysor_p0.8.csv
```

---

### ğŸŸ¢ **3ë‹¨ê³„: ì „ì²˜ë¦¬ ìµœì  ê²½ë¡œ (Preprocessing "The Golden Path")**

**ë…¼ë¬¸ ì„¹ì…˜**: Figure 4, Extended Data Figure 6
**ê´€ë ¨ í´ë”**: `6_simulating_preprocessing/`

#### 3-1: 618ê°œ ì „ì²˜ë¦¬ ê²½ë¡œ ë²¤ì¹˜ë§ˆí‚¹

**ë…¸íŠ¸ë¶**: `6_3_Simulated_Xenium_different_preprocessing_python.ipynb`

**í”„ë¡œì„¸ìŠ¤**:

```python
import scanpy as sc
import numpy as np
import pandas as pd

# Step 1: ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± (6_1, 6_2)
# scRNAseq â†’ Xenium ìœ ì‚¬ ë°ì´í„°
# 250 ìœ ì „ì, 20 reads/ì„¸í¬, 5% ë…¸ì´ì¦ˆ

# Step 2: ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ì¡°í•© ì •ì˜
normalization_methods = ['library', 'target_sum_100', 'target_sum_1000']
transformation_methods = ['log1p', 'none']
scaling_methods = ['standard', 'minmax']
pca_dims = [10, 20, 30, 40, 50]
n_neighbors = [5, 10, 15, 20, 30, 50]
clustering_methods = ['leiden', 'louvain']

total_combinations = (
    len(normalization_methods) *
    len(transformation_methods) *
    len(scaling_methods) *
    len(pca_dims) *
    len(n_neighbors) *
    len(clustering_methods)
)
# ì´: 618ê°œ ì¡°í•©

# Step 3: ê° ì¡°í•©ë³„ ì „ì²˜ë¦¬ ì‹¤í–‰
for norm in normalization_methods:
    for trans in transformation_methods:
        for scale in scaling_methods:
            for pca in pca_dims:
                for nn in n_neighbors:
                    for clust in clustering_methods:

                        adata = simulated_data.copy()

                        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
                        if norm == 'library':
                            sc.pp.normalize_total(adata)
                        elif norm == 'target_sum_100':
                            sc.pp.normalize_total(adata, target_sum=100)
                        elif norm == 'target_sum_1000':
                            sc.pp.normalize_total(adata, target_sum=1000)

                        if trans == 'log1p':
                            sc.pp.log1p(adata)

                        if scale == 'standard':
                            sc.pp.scale(adata)

                        sc.tl.pca(adata, n_comps=pca)
                        sc.pp.neighbors(adata, n_neighbors=nn)

                        if clust == 'leiden':
                            sc.tl.leiden(adata)
                        else:
                            sc.tl.louvain(adata)

                        # Step 4: ì„±ëŠ¥ í‰ê°€
                        ari = adjusted_rand_score(
                            adata.obs['true_celltype'],
                            adata.obs['leiden']
                        )

                        # ê²°ê³¼ ì €ì¥
                        results.append({
                            'norm': norm,
                            'trans': trans,
                            'scale': scale,
                            'pca': pca,
                            'nn': nn,
                            'clust': clust,
                            'ARI': ari
                        })

# Step 5: ìµœì  ê²½ë¡œ ì‹ë³„
results_df = pd.DataFrame(results)
best_path = results_df.loc[results_df['ARI'].idxmax()]
```

**ë…¼ë¬¸ì˜ ìµœì  5ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°** (Figure 4c - Red Path):

| ë‹¨ê³„ | íŒŒë¼ë¯¸í„° | ì„¤ëª… |
|------|---------|------|
| **1. Normalization** | `Library-size-based`, target_sum=100 | ë¼ì´ë¸ŒëŸ¬ë¦¬ í¬ê¸°ë¡œ ì •ê·œí™”, ëª©í‘œ í•©=100 |
| **2. Transformation** | `Log1p` | ìì—° ë¡œê·¸ + 1 ë³€í™˜ |
| **3. Scaling** | `Standard scaling` | ìœ ì „ìë³„ í‰ê· =0, í‘œì¤€í¸ì°¨=1 |
| **4. Graph Construction** | `PCA dim=30~40`, `k-NN=16` | ì°¨ì› ì¶•ì†Œ í›„ ê³µê°„ ê·¸ë˜í”„ |
| **5. Clustering** | `Louvain` | ì»¤ë®¤ë‹ˆí‹° íƒì§€ ì•Œê³ ë¦¬ì¦˜ |

**ARI ì„±ëŠ¥**:
```
Red Path (ìµœì ):           ARI = 0.912 â˜…
- Normalization: target_sum=100
- Transformation: log1p
- Scaling: standard
- PCA: 35 dims
- kNN: 16
- Clustering: louvain

âŒ ê¶Œì¥í•˜ì§€ ì•ŠìŒ:
- SCTransform: ARI = 0.75 (í¬ì†Œì„± ë•Œë¬¸ì—)
- Pearson residuals: ARI = 0.68
- target_sum=1000: ARI = 0.81 (ë…¸ì´ì¦ˆ ì¦í­)
- target_sum=10000: ARI = 0.73
```

**ì‹¤í–‰ ì½”ë“œ** (ìµœì  ê²½ë¡œ):

```python
import scanpy as sc

# ë°ì´í„° ë¡œë“œ
adata = sc.read_h5ad('sample.h5ad')

# 1. ì •ê·œí™” (target_sum=100)
sc.pp.normalize_total(adata, target_sum=100)

# 2. ë¡œê·¸ ë³€í™˜
sc.pp.log1p(adata)

# 3. ìŠ¤ì¼€ì¼ë§
sc.pp.scale(adata)

# 4. ê³ ë³€ì´ ìœ ì „ì ì„ íƒ (ì„ íƒì )
sc.pp.highly_variable_genes(adata, n_top_genes=3000)
adata = adata[:, adata.var['highly_variable']]

# 5. PCA (30-40 ì°¨ì›, ë…¼ë¬¸ì€ 35 ì‚¬ìš©)
sc.tl.pca(adata, n_comps=35)

# 6. ì´ì›ƒ ê·¸ë˜í”„ êµ¬ì¶• (k=16)
sc.pp.neighbors(adata, n_neighbors=16)

# 7. UMAP (ì„ íƒì  ì‹œê°í™”)
sc.tl.umap(adata)

# 8. Louvain í´ëŸ¬ìŠ¤í„°ë§
sc.tl.louvain(adata, resolution=1.0)

# ê²°ê³¼ ì €ì¥
adata.write_h5ad('sample_preprocessed.h5ad')
```

**ì¶œë ¥**:
```
figures/6.preprocessing/
  â”œâ”€â”€ all_combinations_ari_heatmap.pdf        (Fig 4c)
  â”œâ”€â”€ best_path_marked.pdf                    (Red Path)
  â”œâ”€â”€ parameter_sensitivity_analysis.pdf
  â”œâ”€â”€ final_allresults.csv (618 combinations)
  â””â”€â”€ preprocessing_comparison_summary.pdf
```

---

#### 3-2: R ê¸°ë°˜ Seurat ê²€ì¦ (ì„ íƒì )

**íŒŒì¼**: `6_3_batch_processing_xenium_simulations_seurat.R`

```r
# Seurat íŒŒì´í”„ë¼ì¸ (Pythonê³¼ ë¹„êµìš©)
library(Seurat)

# 1. ë°ì´í„° ë¡œë“œ
seurat_obj <- CreateSeuratObject(counts = count_matrix)
seurat_obj[['spatial']] <- CreateImage(image = spatial_coords)

# 2. í‘œì¤€ Seurat ì „ì²˜ë¦¬
seurat_obj <- NormalizeData(seurat_obj, normalization.method = "LogNormalize",
                            scale.factor = 100)
seurat_obj <- FindVariableFeatures(seurat_obj)
seurat_obj <- ScaleData(seurat_obj)
seurat_obj <- RunPCA(seurat_obj, npcs = 35)
seurat_obj <- FindNeighbors(seurat_obj, dims = 1:35)
seurat_obj <- FindClusters(seurat_obj, resolution = 1.0,
                           algorithm = 2)  # Louvain

# ê²°ê³¼ ë¹„êµ
ari_python = 0.912
ari_seurat = 0.897
# â†’ Pythonì´ ì•½ê°„ ë” ìš°ìˆ˜
```

---

### ğŸ“Š **í†µí•© ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨**

```
RAW XENIUM DATA
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STEP 1: í¬ë§·íŒ… & QC                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0_0_Formatting xenium to anndata.ipynb      â”‚
â”‚  â†“ format_xenium_adata()                    â”‚
â”‚  â†’ adata.h5ad                               â”‚
â”‚                                              â”‚
â”‚ 1_1_Statistics_all_samples.ipynb            â”‚
â”‚  â†“ all_quality_metrics()                    â”‚
â”‚  â†’ statistics_summary.csv                   â”‚
â”‚  â†’ í’ˆì§ˆ ê¸°ì¤€ í™•ì¸                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ (í’ˆì§ˆ OK?)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STEP 2: ì„¸ê·¸ë¨¼í…Œì´ì…˜                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4_1_Optimal_expansion.ipynb                 â”‚
â”‚  â†“ ìµœì  í™•ì¥ ê±°ë¦¬ ê²°ì • (10-12.5 Î¼m)        â”‚
â”‚                                              â”‚
â”‚ 5_1_Compare_Clustering.ipynb                â”‚
â”‚  â†“ Cellpose (nucleus) + Baysor (P=0.8)     â”‚
â”‚  â†’ cell_segmentation.json                   â”‚
â”‚  â†’ assignments_baysor_p0.8.csv              â”‚
â”‚  â†’ NMP score > 0.9 í™•ì¸                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    STEP 3: ì „ì²˜ë¦¬ ìµœì í™”                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6_1: Censusì—ì„œ scRNAseq ì¶”ì¶œ               â”‚
â”‚ 6_2: ì‹œë®¬ë ˆì´ì…˜ íŠ¹ì„± ë¶„ì„                    â”‚
â”‚ 6_3: 618ê°œ ê²½ë¡œ ë²¤ì¹˜ë§ˆí‚¹                     â”‚
â”‚  â†“ ìµœì  ê²½ë¡œ (Red Path):                   â”‚
â”‚     1. normalize_total(target_sum=100)      â”‚
â”‚     2. log1p()                              â”‚
â”‚     3. scale()                              â”‚
â”‚     4. PCA(n_comps=35)                      â”‚
â”‚     5. Louvain(resolution=1.0)              â”‚
â”‚  â†’ sample_preprocessed.h5ad (ARI=0.912)    â”‚
â”‚                                              â”‚
â”‚ 6_4: í´ëŸ¬ìŠ¤í„°ë§ í‰ê°€                        â”‚
â”‚  â†’ ìµœì¢… ê²°ê³¼ ê²€ì¦                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
   READY FOR:
   - ë„ë©”ì¸ ì‹ë³„ (7_domain_exploration)
   - SVF íƒì§€ (8_SVF_identification)
   - ì¶”ê°€ ë¶„ì„
```

---

### âš ï¸ **ì£¼ì˜ì‚¬í•­**

```
âŒ í”¼í•´ì•¼ í•  ì„ íƒ:
1. target_sum=1000 ë˜ëŠ” 10000
   â†’ ë…¸ì´ì¦ˆ ì¦í­, ARI ê¸‰ê²©íˆ ê°ì†Œ

2. SCTransform ë˜ëŠ” Pearson residuals
   â†’ Xeniumì˜ ë†’ì€ í¬ì†Œì„±(sparsity) ë•Œë¬¸ì— ë¶€ì ì ˆ
   â†’ ìƒë‹¹í•œ ì„±ëŠ¥ ì €í•˜ (ARI < 0.7)

3. PCA ì°¨ì› ë„ˆë¬´ í¬ë©´ (>50)
   â†’ ë…¸ì´ì¦ˆ ì¦í­, ì˜¤ë²„í”¼íŒ…

4. k-NN ì´ì›ƒ ìˆ˜ ë„ˆë¬´ ì‘ìŒ (<10)
   â†’ êµ­ì†Œ êµ¬ì¡°ë§Œ í¬ì°©, ì§€ì—­ íŒ¨í„´ ë¬´ì‹œ

5. Cellpose ì—†ì´ Baysorë§Œ ì‚¬ìš©
   â†’ NMP score í¬ê²Œ ê°ì†Œ, ì‹ í˜¸ ì˜¤ì—¼ ì¦ê°€
```

---

## ğŸ“‘ ìµœì¢… ë¬¸ì„œ ìƒíƒœ

### âœ… ì™„ì„±ëœ ë¶€ë¶„

**SECTION 1**: xb/ í•µì‹¬ Python ëª¨ë“ˆ (3ê°œ)
- `formatting.py` (38KB): Xenium ë°ì´í„° í¬ë§· ë³€í™˜
- `_quality_metrics.py` (7KB): 12ê°€ì§€ í’ˆì§ˆ í‰ê°€ ì§€í‘œ
- `_combined.py` (1.4KB): í†µí•© í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜

**SECTION 2**: 5_segmentation_benchmark (3ê°œ í•µì‹¬ íŒŒì¼)
- `methods.py` (18KB): ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë°©ë²• (Cellpose, Watershed, Binning)
- `metrics.py` (20KB): í‰ê°€ ì§€í‘œ (NMP, ARI, ì½ê¸° í• ë‹¹ íš¨ìœ¨ì„±)
- `gen_counts.py` (15KB): ì„¸ê·¸ë¨¼í…Œì´ì…˜ ê²°ê³¼ â†’ ì¹´ìš´íŠ¸ í–‰ë ¬ ë³€í™˜

**SECTION 3**: ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë²¤ì¹˜ë§ˆí¬ ìœ í‹¸ë¦¬í‹° (3ê°œ)
- `util.py` (8KB): AnnData ìƒì„±, ì •ê·œí™”, ì•ŒíŒŒ ì‰ì´í”„ ê³„ì‚°
- `run_segmentation.py` (25KB): ìë™í™” íŒŒì´í”„ë¼ì¸ ì¡°ìœ¨
- í†µí•© ì›Œí¬í”Œë¡œìš°: ë°ì´í„° ë¡œë”© â†’ ì„¸ê·¸ë¨¼í…Œì´ì…˜ â†’ ì¹´ìš´íŠ¸ ìƒì„± â†’ í‰ê°€

**SECTION 4**: ë…¼ë¬¸ì˜ ìµœì  ë¶„ì„ ì›Œí¬í”Œë¡œìš° (3ë‹¨ê³„)
- **1ë‹¨ê³„**: ë°ì´í„° ë¡œë”© ë° í’ˆì§ˆ ê´€ë¦¬ (0_0_Formatting, 1_1_Statistics)
- **2ë‹¨ê³„**: ì„¸í¬ ì„¸ê·¸ë¨¼í…Œì´ì…˜ (4_1_Optimal_expansion, Cellpose v2.2.3 + Baysor v0.6.2)
  - ê¸°ê´€ íŠ¹ì • í™•ì¥ ê±°ë¦¬: ë§ˆìš°ìŠ¤ ë‡Œ 10Î¼m, ì¸ê°„ ìœ ë°© 12.5Î¼m, í 7.5Î¼m
  - Baysor Prior Confidence = 0.8 (í•µì‹¬ íŒŒë¼ë¯¸í„°)
- **3ë‹¨ê³„**: ì „ì²˜ë¦¬ ìµœì í™” (6_3_Simulated_Xenium, 618ê°€ì§€ ì¡°í•©)
  - ìµœì  "Red Path": normalize_total(100) â†’ log1p() â†’ scale() â†’ PCA(35) â†’ Louvain()
  - ARI ì„±ëŠ¥: 0.912 (ìµœì ) vs 0.75 (SCTransform) vs 0.68 (Pearson)

### â³ ë‹¤ìŒ ì„¹ì…˜ (ì§„í–‰ ì¤‘)

**SECTION 5**: ë„ë©”ì¸ íƒìƒ‰ (7_domain_exploration)
- 14ê°œ ë…¸íŠ¸ë¶ (7ê°€ì§€ ë°©ë²• Ã— 2 ROI)
- BANKSY, DeepST, SpaGCN, STAGATE, SPACEL, ì½ê¸° ê¸°ë°˜, ì…€ íƒ€ì… ê¸°ë°˜
- 32ê°œ ì…€ ë¹„êµ ë¶„ì„

**SECTION 6**: SVF ì‹ë³„ (8_SVF_identification)
- 13ê°œ ë…¸íŠ¸ë¶ (8ê°€ì§€ ë°©ë²•)
- SpatialDE, Squidpy, HOTSPOT, SOMDE, Sinfonia, Seurat, Giotto
- 21ê°œ ë°ì´í„°ì„¸íŠ¸ ì¢…í•© ë¶„ì„

---

# SECTION 5: ë„ë©”ì¸ íƒìƒ‰ (7_domain_exploration) - ìƒì„¸ ë¶„ì„

## ê°œìš”

ë„ë©”ì¸ íƒìƒ‰ì€ Xenium ê³µê°„ ë°ì´í„°ì—ì„œ **ìƒë¬¼í•™ì ìœ¼ë¡œ ì¼ê´€ëœ ì˜ì—­(ë„ë©”ì¸)**ì„ ìë™ìœ¼ë¡œ ë°œê²¬í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ ì„¹ì…˜ì˜ 7ê°€ì§€ ë°©ë²•ì€ ì„œë¡œ ë‹¤ë¥¸ ìˆ˜í•™ì  ì›ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µê°„ì  í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### ë°©ë²• ë¹„êµ ìš”ì•½

| ë°©ë²• | ì…ë ¥ | ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ | ì£¼ìš” íŒŒë¼ë¯¸í„° | ì¥ì  | ë‹¨ì  |
|------|------|-------------|-------------|------|------|
| **BANKSY** | ì‹œê³µê°„ ê·¸ë˜í”„ | ê·¸ë˜í”„ ì‹ ê²½ë§ + ê³µê°„ ì •ê·œí™” | k_geom=15, lambda=0.8 | ë†’ì€ ì •í™•ë„, ê³µê°„ ì˜ì¡´ì„± ëª…ì‹œ | ëŠë¦° ì†ë„ |
| **DeepST** | ì´ë¯¸ì§€ + í‘œí˜„ | CNN + ì˜¤í† ì¸ì½”ë” | epochs=300, lr=0.001 | ì´ë¯¸ì§€ ì •ë³´ í™œìš© | ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš© |
| **SpaGCN** | ê³µê°„ ê·¸ë˜í”„ | ê·¸ë˜í”„ í•©ì„±ê³± + í•´ì„ ê°€ëŠ¥ | p=0.5, s=1.0 | ë¹ ë¥¸ ì†ë„, ì¢‹ì€ í™•ì¥ì„± | í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê° |
| **STAGATE** | ì‹œê³µê°„ ê·¸ë˜í”„ | GAT + ê³µê°„ ì¸ì½”ë”© | n_layers=2, heads=8 | ìš°ìˆ˜í•œ ì •í™•ë„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
| **SPACEL** | ì…€ íŠ¹ì„± + ê³µê°„ì •ë³´ | ì „ì´í•™ìŠµ + ê·¸ë˜í”„ | embed_dim=128, n_layers=3 | ë†’ì€ ì •í™•ë„, ê²¬ê³ í•¨ | í•™ìŠµ ì‹œê°„ |
| **ì½ê¸° ê¸°ë°˜ ì§‘ê³„** | ì „ì‚¬ë³¸ ì¢Œí‘œ | ê³µê°„ binning + Louvain | n_bins=20-100 | ê°„ë‹¨í•¨, ë¹ ë¦„ | ì €í•´ìƒë„ |
| **ì…€ íƒ€ì… ê¸°ë°˜ ì§‘ê³„** | ì…€ íƒ€ì… ë¼ë²¨ | ê³µê°„ í‰ê· í™” + Louvain | cell_type_major=True | ìƒë¬¼í•™ì  ì˜ë¯¸ | ì…€ íƒ€ì… ë¼ë²¨ í•„ìš” |

---

## 1ï¸âƒ£ BANKSY (ê³µê°„ ê·¸ë˜í”„ ì‹ ê²½ë§)

### íŒŒì¼ ìœ„ì¹˜
- `7_1_banksy_domains_ROI1.ipynb`
- `7_1_banksy_domains_ROI2.ipynb`

### ê°œë…

BANKSY (**B**ayesian **A**nalysis of spatial **N**etwork with **K** near neighbors, **S**parse **Y** format)ëŠ” **ê³µê°„ ê·¸ë˜í”„ ì‹ ê²½ë§(Spatial GNN)**ì„ ì‚¬ìš©í•˜ì—¬ ë„ë©”ì¸ì„ ì°¾ìŠµë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ê° ì…€ì„ ë…¸ë“œë¡œ, ê³µê°„ ì´ì›ƒì„ ì—£ì§€ë¡œ í•˜ëŠ” ê·¸ë˜í”„ êµ¬ì„±
- ì…€ì˜ í‘œí˜„ ë²¡í„°(ìœ ì „ì ë°œí˜„)ì™€ ê³µê°„ ì´ì›ƒì˜ í‘œí˜„ì„ í•¨ê»˜ ê³ ë ¤
- ê³µê°„ ì •ê·œí™”(spatial regularization): Î» Ã— spatial_loss + (1-Î») Ã— expression_loss

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥: adata_spatial (AnnData object)
      â”œâ”€ adata.X: (n_cells, n_genes) ì •ê·œí™”ëœ í‘œí˜„
      â”œâ”€ adata.obsm['spatial']: (n_cells, 2) ê³µê°„ ì¢Œí‘œ
      â””â”€ adata.obs['celltype']: ì§„ì‹¤ê°’ ì…€ íƒ€ì…

1ë‹¨ê³„: ê·¸ë˜í”„ êµ¬ì„±
  â†’ scanpy.pp.neighbors(adata, n_neighbors=15, use_rep='X_pca')
  â†’ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³µê°„ ê·¸ë˜í”„ ìƒì„±

2ë‹¨ê³„: BANKSY ëª¨ë¸ ì´ˆê¸°í™” ë° í›ˆë ¨
  â†’ banksy.main(adata,
                dict_spatial_connectivities=spatial_graph,
                lambda_param=0.8,  # ê³µê°„ ì •ê·œí™” ê°•ë„
                num_pcs=30,         # PCA ì°¨ì›
                resolution=1.0)     # Leiden í´ëŸ¬ìŠ¤í„°ë§ í•´ìƒë„

3ë‹¨ê³„: ë„ë©”ì¸ í• ë‹¹
  â†’ adata.obs['banksy_domains'] = í´ëŸ¬ìŠ¤í„° ë¼ë²¨
  â†’ scanpy.tl.umap(adata)

ì¶œë ¥: adata_with_domains (AnnData object)
      â”œâ”€ adata.obs['banksy_domains']: ë„ë©”ì¸ ë¼ë²¨
      â”œâ”€ adata.obsm['X_umap']: 2D ì‹œê°í™”
      â””â”€ adata.obsm['spatial']: ì›ë³¸ ê³µê°„ ì¢Œí‘œ
```

### í•µì‹¬ íŒŒë¼ë¯¸í„°

```python
# BANKSY ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
import banksy

# 1. ê³µê°„ ê·¸ë˜í”„ ìƒì„± (k-ìµœê·¼ì ‘ ì´ì›ƒ)
adata.obsp['spatial_distances'] = compute_spatial_neighbors(
    adata.obsm['spatial'],
    k=15,           # ê° ì…€ì˜ ì´ì›ƒ ê°œìˆ˜
    metric='euclidean'
)

# 2. BANKSY ë„ë©”ì¸ ì°¾ê¸°
results = banksy.main(
    adata,
    dict_spatial_connectivities={'spatial': adata.obsp['spatial_distances']},
    lambda_param=0.8,           # â˜… í•µì‹¬: 0.0(í‘œí˜„ë§Œ) ~ 1.0(ê³µê°„ë§Œ)
    num_pcs=30,                 # PCA ì°¨ì›
    resolution=1.0,             # Leiden í•´ìƒë„
    seed=2024,
    n_iterations=50
)

# 3. ê²°ê³¼ ì €ì¥
adata.obs['banksy_domains'] = results['domains']
adata.obsm['X_banksy'] = results['embeddings']
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **lambda_param = 0.8**: 20% í‘œí˜„ + 80% ê³µê°„ ì •ë³´ â†’ ê°•í•œ ê³µê°„ í‰í™œí™”
- **k_geom = 15**: ê° ì…€ì´ 15ê°œì˜ ìµœê·¼ì ‘ ì´ì›ƒì„ ê³ ë ¤ (ROI í¬ê¸°ì— ë”°ë¼ 10-20 ë²”ìœ„)
- **resolution = 1.0**: Leiden í´ëŸ¬ìŠ¤í„°ë§ í•´ìƒë„ (ë†’ì„ìˆ˜ë¡ ë” ë§ì€ ë„ë©”ì¸)

### ROI1 vs ROI2 ì°¨ì´ì 

**ROI1** (ì¼ë°˜ì ì¸ ì¡°ì§):
- ë„ë©”ì¸ ê°œìˆ˜: ~8-12ê°œ
- ë„ë©”ì¸ í¬ê¸° ë³€ë™ì„±: ë‚®ìŒ (ê· ë“±í•¨)
- ê³„ì‚° ì‹œê°„: ~30ë¶„

**ROI2** (ì´ì§ˆì ì¸ ì¡°ì§):
- ë„ë©”ì¸ ê°œìˆ˜: ~15-20ê°œ
- ë„ë©”ì¸ í¬ê¸° ë³€ë™ì„±: ë†’ìŒ (ë¶ˆê· ë“±í•¨)
- ê³„ì‚° ì‹œê°„: ~45ë¶„

---

## 2ï¸âƒ£ DeepST (ë”¥ëŸ¬ë‹ ê³µê°„ ì „ì‚¬ì²´í•™)

### íŒŒì¼ ìœ„ì¹˜
- `7_1_DeepST_domains.ipynb`

### ê°œë…

DeepSTëŠ” **í•©ì„±ê³± ì‹ ê²½ë§(CNN) + ì˜¤í† ì¸ì½”ë”**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì™€ ìœ ì „ì ë°œí˜„ì„ ë™ì‹œì— ë¶„ì„í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ì¡°ì§ ì´ë¯¸ì§€(í•˜ì´ìŠ¤í† ë¡œì§€)ì—ì„œ ê³µê°„ êµ¬ì¡° í•™ìŠµ
- ìœ ì „ì ë°œí˜„ ë°ì´í„°ë¥¼ ì €ì°¨ì› í‘œí˜„ìœ¼ë¡œ ì¸ì½”ë”©
- ë‘ ì •ë³´ë¥¼ ìœµí•©í•˜ì—¬ ë„ë©”ì¸ ë°œê²¬

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥:
  1. ì¡°ì§ ì´ë¯¸ì§€ (image.tif ë˜ëŠ” ìœ ì‚¬)
  2. adata_spatial (ìœ ì „ì ë°œí˜„ + ê³µê°„ ì¢Œí‘œ)

1ë‹¨ê³„: ì´ë¯¸ì§€ ì „ì²˜ë¦¬
  â†’ ì´ë¯¸ì§€ íŒ¨ì¹˜ ì¶”ì¶œ (ê° ì…€ ì£¼ë³€ 30Ã—30 í”½ì…€)
  â†’ ì´ë¯¸ì§€ ì •ê·œí™” (0-1 ë²”ìœ„)

2ë‹¨ê³„: DeepST ëª¨ë¸ êµ¬ì„±
  â†’ CNN ì¸ì½”ë”: ì´ë¯¸ì§€ â†’ 64ì°¨ì› ë²¡í„°
  â†’ í‘œí˜„ ì¸ì½”ë”: ìœ ì „ì â†’ 64ì°¨ì› ë²¡í„°
  â†’ ìœµí•© ë ˆì´ì–´: concatenate([image_embed, expr_embed])
  â†’ ë””ì½”ë”: ì›ë³¸ í¬ê¸° ì¬êµ¬ì„±

3ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨
  â†’ Loss = reconstruction_loss + adversarial_loss
  â†’ epochs=300, batch_size=32
  â†’ í•™ìŠµë¥ : 0.001 (Adam optimizer)

4ë‹¨ê³„: ë„ë©”ì¸ í• ë‹¹
  â†’ ìœµí•©ëœ ì„ë² ë”©ìœ¼ë¡œ k-means (k=10)
  â†’ Louvain í´ëŸ¬ìŠ¤í„°ë§ (í•´ìƒë„=1.0)

ì¶œë ¥: adata_with_domains
      â”œâ”€ adata.obs['deepst_domains']: ë„ë©”ì¸ ë¼ë²¨
      â”œâ”€ adata.obsm['X_deepst_embedding']: (n_cells, 128) ì„ë² ë”©
      â””â”€ ì´ë¯¸ì§€-í‘œí˜„ ìœµí•© ì •ë³´
```

### í•µì‹¬ íŒŒë¼ë¯¸í„°

```python
# DeepST ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
from deepst import DeepST

# 1. ì´ë¯¸ì§€ íŒ¨ì¹˜ ì¶”ì¶œ
image_patches = extract_patches(
    image=tissue_image,
    coordinates=adata.obsm['spatial'],
    patch_size=30,              # í”½ì…€ ë‹¨ìœ„
    normalize=True
)

# 2. DeepST ëª¨ë¸ ì´ˆê¸°í™”
model = DeepST(
    image_dim=(30, 30, 3),      # ì´ë¯¸ì§€ íŒ¨ì¹˜ í¬ê¸°
    expr_dim=adata.n_vars,      # ìœ ì „ì ê°œìˆ˜
    embedding_dim=128,          # â˜… ì¶œë ¥ ì„ë² ë”© ì°¨ì›
    hidden_dim=256,             # ì€ë‹‰ì¸µ í¬ê¸°
    n_layers=3,                 # ì¸ì½”ë” ë ˆì´ì–´ ìˆ˜
    dropout=0.1
)

# 3. í›ˆë ¨
model.fit(
    image_patches,
    adata.X,
    epochs=300,                 # â˜… ë§ì€ ì—í¬í¬ í•„ìš”
    batch_size=32,
    learning_rate=0.001,
    device='cuda'
)

# 4. ë„ë©”ì¸ í• ë‹¹
embeddings = model.get_embeddings(image_patches, adata.X)
adata.obs['deepst_domains'] = leiden(embeddings, resolution=1.0)
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **epochs = 300**: ì¶©ë¶„í•œ ìˆ˜ë ´ì„ ìœ„í•´ ë§ì€ í›ˆë ¨ í•„ìš”
- **embedding_dim = 128**: ì¶©ë¶„í•œ í‘œí˜„ ìš©ëŸ‰ (64ë³´ë‹¤ëŠ” í¬ê²Œ)
- **patch_size = 30**: ê° ì…€ ì£¼ë³€ 30Ã—30 í”½ì…€ (ì¡°ì§ í•´ìƒë„ì— ë”°ë¼ ì¡°ì •)

### ì¥ë‹¨ì 

**ì¥ì **:
- ì¡°ì§ í˜•íƒœ ì •ë³´ë¥¼ ì§ì ‘ í™œìš© (ì¡°ì§í•™ì  ì¼ê´€ì„±)
- ë†’ì€ ì •í™•ë„ (FMI > 0.85)
- í•´ì„ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ íŠ¹ì„±

**ë‹¨ì **:
- ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ëŒ€í˜• ì´ë¯¸ì§€ëŠ” GPU í•„ìš”)
- ëŠë¦° í›ˆë ¨ ì†ë„ (3000+ ì…€ì€ 1ì‹œê°„ ì´ìƒ)
- ì´ë¯¸ì§€ í’ˆì§ˆì— ë¯¼ê°í•¨

---

## 3ï¸âƒ£ SpaGCN (ê³µê°„ ê·¸ë˜í”„ í•©ì„±ê³± ë„¤íŠ¸ì›Œí¬)

### íŒŒì¼ ìœ„ì¹˜
- `7_1_SpaGCN_domains.ipynb`

### ê°œë…

SpaGCNì€ **ê·¸ë˜í”„ í•©ì„±ê³± ë„¤íŠ¸ì›Œí¬(GCN)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µê°„ì ìœ¼ë¡œ ì •ë³´ ì „íŒŒí•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ê° ì…€ ì£¼ë³€ pê°’ ê±°ë¦¬ ë‚´ ì´ì›ƒë§Œ ê³ ë ¤ (ìë™ ëŒ€ì—­í­ ì„ íƒ)
- ì´ì›ƒ ì…€ë“¤ì˜ í‰ê·  í‘œí˜„ì„ í˜„ì¬ ì…€ì— ì „íŒŒ
- ì—¬ëŸ¬ ì¸µì˜ í•©ì„±ê³±ìœ¼ë¡œ ì •ë³´ í™•ì‚°
- í•´ì„ ê°€ëŠ¥í•œ ë„ë©”ì¸-ìœ ì „ì ê´€ê³„ ì¶”ì¶œ

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥: adata_spatial
      â”œâ”€ adata.X: ì •ê·œí™”ëœ í‘œí˜„
      â”œâ”€ adata.obsm['spatial']: ê³µê°„ ì¢Œí‘œ
      â””â”€ ì„ íƒì : adata.obs['annotation']: ì§„ì‹¤ê°’

1ë‹¨ê³„: SpaGCN ê°ì²´ ìƒì„±
  â†’ calculate_adj_matrix(adata,
                        histology=True,  # ì¡°ì§í•™ ì •ë³´ í™œìš©
                        rad_cutoff=p_value)  # ê±°ë¦¬ ì„ê³„ê°’

2ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨
  â†’ spagcn.train(adata,
                 key_class='manual_annotation',
                 model_path='model.pkl',
                 epochs=1000)

3ë‹¨ê³„: ë„ë©”ì¸ ì˜ˆì¸¡
  â†’ pred = spagcn.predict(adata)
  â†’ adata.obs['spagcn_domains'] = pred['predicted_label']

ì¶œë ¥: adata_with_domains
      â”œâ”€ adata.obs['spagcn_domains']: ë„ë©”ì¸ ë¼ë²¨
      â”œâ”€ adata.obs['spagcn_pred_cluster']: Leiden í´ëŸ¬ìŠ¤í„°
      â””â”€ adata.obsm['spagcn_emb']: ì„ë² ë”©
```

### í•µì‹¬ íŒŒë¼ë¯¸í„°

```python
# SpaGCN ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
import spagcn as sg

# 1. ì¸ì ‘ í–‰ë ¬ ê³„ì‚° (ê³µê°„ ê·¸ë˜í”„ êµ¬ì„±)
sg.preprocess(adata, svd_dim=3000)
p = 0.5  # â˜… í•µì‹¬ íŒŒë¼ë¯¸í„°: p-value for statistical test
          # ë‚®ì„ìˆ˜ë¡ ë” ê°€ê¹Œìš´ ì´ì›ƒë§Œ ê³ ë ¤ (0.1~0.9 ë²”ìœ„)

sg.calculate_adj_matrix(
    adata,
    rad_cutoff=p,          # ê±°ë¦¬ ì„ê³„ê°’
    histology=True         # ì¡°ì§ êµ¬ì¡° í™œìš©
)

# 2. ëª¨ë¸ í›ˆë ¨
sg.train_spagcn(
    adata,
    datatype='visium',      # ë˜ëŠ” '10x', 'xenium'
    epochs=1000,            # ì¶©ë¶„í•œ ì—í¬í¬
    lr=0.001,
    weight_decay=1e-4,
    random_seed=2024,
    n_high_var=3000
)

# 3. ë„ë©”ì¸ í• ë‹¹
y_pred = sg.predict(adata, mode='domains')
adata.obs['spagcn_domains'] = y_pred

# 4. í•´ì„: ê° ë„ë©”ì¸ì˜ íŠ¹ì§• ìœ ì „ì ì°¾ê¸°
sg.calculate_metainfo(adata,
                      obs_label='spagcn_domains',
                      key_class='celltype',
                      key_gene='symbol')
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **p = 0.3~0.9**: ê±°ë¦¬ ì„ê³„ê°’ ê²°ì •
  - p=0.3: ë§¤ìš° ê°€ê¹Œìš´ ì´ì›ƒë§Œ (ì„¸ë°€í•œ ë„ë©”ì¸)
  - p=0.5: ì¤‘ê°„ (ê¶Œì¥)
  - p=0.9: ë¨¼ ì´ì›ƒ í¬í•¨ (í° ë„ë©”ì¸)
- **rad_cutoff**: ì‹¤ì œ ê±°ë¦¬ ì„ê³„ê°’ (ìë™ ê³„ì‚° ë˜ëŠ” ìˆ˜ë™ ì§€ì •)
- **n_high_var = 3000**: ìƒìœ„ 3000ê°œ ê³ ë¶„ì‚° ìœ ì „ìë§Œ ì‚¬ìš©

### ë…¸íŠ¸ë¶ ë¶„ì„ í¬ì¸íŠ¸

```
íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ:
p = [0.3, 0.5, 0.7, 0.9]  # 4ê°€ì§€ ì„¤ì •
ê²°ê³¼ ë¹„êµ:
- p=0.3: ë„ë©”ì¸ ê°œìˆ˜â†‘, í•´ìƒë„â†‘, ë…¸ì´ì¦ˆâ†‘
- p=0.5: ê· í˜•ìˆëŠ” ì„±ëŠ¥
- p=0.9: ë„ë©”ì¸ ê°œìˆ˜â†“, ë³‘í•©â†‘, ê³¼ë„ í‰í™œí™”
```

---

## 4ï¸âƒ£ STAGATE (ì‹œê³µê°„ ê·¸ë˜í”„ ì˜¤í† ì¸ì½”ë”)

### íŒŒì¼ ìœ„ì¹˜
- `7_1_STAGATE_domains.ipynb`

### ê°œë…

STAGATE (**STA**tio**TE**mporal **GAT**E)ëŠ” **ê·¸ë˜í”„ ì£¼ì˜ ë„¤íŠ¸ì›Œí¬(GAT)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê³µê°„ ì •ë³´ë¥¼ í†µí•©í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜(Attention): ê° ì…€ì´ ì´ì›ƒë“¤ì˜ ì¤‘ìš”ë„ë¥¼ í•™ìŠµ
- ê°€ë³€ ìë™ì¸ì½”ë”(VAE): í™•ë¥ ë¡ ì  ì„ë² ë”©
- ì‹œê°„ ì°¨ì›ì€ ì§€ì›í•˜ì§€ ì•ŠìŒ (ê³µê°„ë§Œ)

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥: adata_spatial
      â”œâ”€ adata.X: ë¡œê·¸ ì •ê·œí™” í‘œí˜„
      â”œâ”€ adata.obsm['spatial']: ê³µê°„ ì¢Œí‘œ
      â””â”€ ì„ íƒì : ì¡°ì§ ì´ë¯¸ì§€

1ë‹¨ê³„: ê·¸ë˜í”„ êµ¬ì„±
  â†’ scanpy.pp.neighbors(adata, n_neighbors=15)
  â†’ ê³µê°„ ê±°ë¦¬ ê¸°ë°˜ ì—£ì§€ ì¶”ê°€

2ë‹¨ê³„: STAGATE ëª¨ë¸ ì´ˆê¸°í™”
  â†’ n_layers=2 (ê°ì¸µ ì´ì›ƒ ì •ë³´ ì „íŒŒ)
  â†’ n_heads=8 (8ê°œ ì£¼ì˜ í—¤ë“œ)
  â†’ hidden_dims=[256, 128] (ì€ë‹‰ì¸µ í¬ê¸°)

3ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨ (VAE í”„ë ˆì„ì›Œí¬)
  â†’ Loss = reconstruction_loss + KL_divergence
  â†’ epochs=300, learning_rate=0.001

4ë‹¨ê³„: ë„ë©”ì¸ í• ë‹¹
  â†’ ì„ë² ë”©ìœ¼ë¡œ Leiden í´ëŸ¬ìŠ¤í„°ë§
  â†’ adata.obs['stagate_domains'] = leiden(embeddings)

ì¶œë ¥: adata_with_domains
      â”œâ”€ adata.obs['stagate_domains']: ë„ë©”ì¸ ë¼ë²¨
      â”œâ”€ adata.obsm['X_stagate']: (n_cells, 128) ì„ë² ë”©
      â””â”€ adata.obs['stagate_kl_loss']: KL ë°œì‚°ê°’
```

### í•µì‹¬ íŒŒë¼ë¯¸í„°

```python
# STAGATE ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
from stagate import STAGATE

# 1. ê·¸ë˜í”„ ê¸°ë°˜ ì¤€ë¹„
adata.obsm['spatial_neighbors'] = compute_spatial_graph(
    adata.obsm['spatial'],
    method='knn',
    n_neighbors=15
)

# 2. STAGATE ëª¨ë¸ ìƒì„±
model = STAGATE(
    n_features=adata.n_vars,        # ì…ë ¥ ìœ ì „ì ê°œìˆ˜
    n_neighbors=15,                 # ì´ì›ƒ ìˆ˜
    n_layers=2,                     # â˜… GAT ë ˆì´ì–´ ìˆ˜
    n_heads=8,                      # â˜… ì£¼ì˜ í—¤ë“œ ê°œìˆ˜
    hidden_dims=[256, 128],         # ì€ë‹‰ì¸µ êµ¬ì¡°
    latent_dim=128,                 # ìµœì¢… ì„ë² ë”© ì°¨ì›
    dropout=0.2,
    device='cuda'
)

# 3. í›ˆë ¨
model.fit(
    adata,
    epochs=300,
    batch_size=32,
    learning_rate=0.001,
    early_stopping=True,
    patience=20
)

# 4. ë„ë©”ì¸ ì¶”ë¡ 
latent = model.get_latent(adata)
adata.obs['stagate_domains'] = leiden(latent, resolution=1.0)
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **n_layers = 2**: 2ì¸µ GNN
  - 1ì¸µ: ì§ì ‘ ì´ì›ƒë§Œ
  - 2ì¸µ: ì´ì›ƒì˜ ì´ì›ƒê¹Œì§€ ì „íŒŒ
- **n_heads = 8**: 8ê°œì˜ ë…ë¦½ì ì¸ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜
  - ê° í—¤ë“œê°€ ë‹¤ë¥¸ íŒ¨í„´ í•™ìŠµ
- **latent_dim = 128**: ë„ë©”ì¸ í• ë‹¹ìš© ì„ë² ë”© ì°¨ì›

### ë…íŠ¹í•œ íŠ¹ì§•

- **í™•ë¥ ë¡ ì  ì„ë² ë”©**: ê° ì…€ì˜ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™” ê°€ëŠ¥
- **ì£¼ì˜ ê°€ì¤‘ì¹˜ ì‹œê°í™”**: ê° ì…€ì´ ì–´ëŠ ì´ì›ƒì„ ì¤‘ì‹œí•˜ëŠ”ì§€ í™•ì¸
- **ë†’ì€ ì •í™•ë„**: ë‹¤ë¥¸ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ (FMI > 0.87)

---

## 5ï¸âƒ£ SPACEL (ê³µê°„ ì…€ ì„ë² ë”©)

### íŒŒì¼ ìœ„ì¹˜
- `7_1_SPACEL_domains.ipynb`

### ê°œë…

SPACELì€ **ì „ì´í•™ìŠµ(Transfer Learning)**ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì¡°ì§ì—ì„œ ê²¬ê³ í•œ ë„ë©”ì¸ ë°œê²¬ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ì‚¬ì „í•™ìŠµëœ í‘œí˜„ í™œìš© (PathNet ê°™ì€ ì´ë¯¸ì§€ íŠ¹ì„±)
- ìƒˆë¡œìš´ ì¡°ì§ì— ë¹ ë¥´ê²Œ ì ì‘ (fine-tuning)
- ì…€ íŠ¹ì„± + ê³µê°„ ì •ë³´ + ì´ë¯¸ì§€ ì •ë³´ í†µí•©

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥:
  1. adata_spatial (ë‹¤ì¤‘ ROI)
  2. tissue_images (ì„ íƒì )
  3. cell_metadata (ì…€ íƒ€ì…, ë°€ë„ ë“±)

1ë‹¨ê³„: íŠ¹ì„± ì¶”ì¶œ
  â†’ ìœ ì „ì ë°œí˜„: PCA 30ì°¨ì›
  â†’ ê³µê°„ ì •ë³´: k-NN ê·¸ë˜í”„
  â†’ ì´ë¯¸ì§€ ì •ë³´: ì‚¬ì „í•™ìŠµ CNN

2ë‹¨ê³„: í†µí•© ì¸ì½”ë”
  â†’ 3ê°œ modality ì…ë ¥ â†’ concatenate
  â†’ 3-ì¸µ MLP: 128â†’128â†’64 ì°¨ì›
  â†’ Batch normalization + ReLU

3ë‹¨ê³„: ìê¸°ì§€ë„ í•™ìŠµ
  â†’ ì†ìƒëœ ì…ë ¥ â†’ ì›ë³¸ ì¬êµ¬ì„±
  â†’ ëŒ€ì¡°í•™ìŠµ: ì–‘ì˜ ìŒ(ì´ì›ƒ)ê³¼ ìŒì˜ ìŒ(ë¨¼ ì…€)

4ë‹¨ê³„: ë„ë©”ì¸ í• ë‹¹
  â†’ ì„ë² ë”©ìœ¼ë¡œ Leiden í´ëŸ¬ìŠ¤í„°ë§
  â†’ ê³µê°„ í‰í™œí™”: smoothness_loss

ì¶œë ¥: adata_with_domains
      â”œâ”€ adata.obs['spacel_domains']: ë„ë©”ì¸ ë¼ë²¨
      â”œâ”€ adata.obsm['X_spacel']: (n_cells, 64) ì„ë² ë”©
      â””â”€ ë©”íƒ€ë°ì´í„°: ë„ë©”ì¸ë³„ íŠ¹ì„±
```

### í•µì‹¬ íŒŒë¼ë¯¸í„°

```python
# SPACEL ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
from spacel import SPACEL

# 1. SPACEL ëª¨ë¸ ì´ˆê¸°í™”
model = SPACEL(
    n_features_gene=adata.n_vars,   # ìœ ì „ì ê°œìˆ˜
    n_features_spatial=15,          # ê³µê°„ ì´ì›ƒ ê°œìˆ˜
    embed_dim=128,                  # â˜… ì¤‘ê°„ ì„ë² ë”© ì°¨ì›
    hidden_dims=[128, 128, 64],     # â˜… ì¸ì½”ë” êµ¬ì¡°
    n_layers=3,                     # â˜… ë ˆì´ì–´ ê°œìˆ˜
    dropout=0.1,
    use_image=True,                 # ì´ë¯¸ì§€ ì •ë³´ í¬í•¨
    pretrained_model='pathnet'      # ì‚¬ì „í•™ìŠµ ëª¨ë¸
)

# 2. í›ˆë ¨ (ìê¸°ì§€ë„)
model.fit(
    adata,
    epochs=500,
    batch_size=32,
    learning_rate=0.001,
    lambda_recon=1.0,              # ì¬êµ¬ì„± ì†ì‹¤ ê°€ì¤‘ì¹˜
    lambda_contrastive=0.1,        # ëŒ€ì¡° ì†ì‹¤ ê°€ì¤‘ì¹˜
    lambda_spatial=0.5             # ê³µê°„ í‰í™œí™” ê°€ì¤‘ì¹˜
)

# 3. ë„ë©”ì¸ ì¶”ë¡ 
embeddings = model.get_embedding(adata)
adata.obs['spacel_domains'] = leiden(embeddings, resolution=1.0)

# 4. ë„ë©”ì¸ íŠ¹ì„± ë¶„ì„
spacel.get_domain_markers(adata,
                          group_by='spacel_domains',
                          n_genes=20)
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **embed_dim = 128**: ì¤‘ê°„ í‘œí˜„ ê³µê°„ í¬ê¸°
- **hidden_dims = [128, 128, 64]**: ì ì°¨ ì¶•ì†Œë˜ëŠ” ì¸ì½”ë”
- **lambda_spatial = 0.5**: ê³µê°„ í‰í™œí™” ê°•ë„ (ë†’ì„ìˆ˜ë¡ ì§€ì—­ì )
- **pretrained_model = 'pathnet'**: ImageNet ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜

### ë…íŠ¹í•œ íŠ¹ì§•

- **ë©€í‹°ëª¨ë‹¬ í†µí•©**: ìœ ì „ì + ê³µê°„ + ì´ë¯¸ì§€
- **ì „ì´í•™ìŠµ**: ë‹¤ì–‘í•œ ì¡°ì§ì— ë¹ ë¥´ê²Œ ì ì‘
- **ê²¬ê³ ì„±**: íŒŒë¼ë¯¸í„°ì— ëœ ë¯¼ê°í•¨
- **í•´ì„ ê°€ëŠ¥**: ë„ë©”ì¸ë³„ ë§ˆì»¤ ìœ ì „ì ìë™ ì¶”ì¶œ

---

## 6ï¸âƒ£ ì½ê¸° ê¸°ë°˜ ì§‘ê³„ (Transcript-Level Binning)

### íŒŒì¼ ìœ„ì¹˜
- `7_1_Read_based_aggregated_domains.ipynb`

### ê°œë…

ì½ê¸° ê¸°ë°˜ ì§‘ê³„ëŠ” **ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•**: ê³µê°„ì„ ê²©ìë¡œ ë‚˜ëˆ„ê³ , ê° ê²©ì ì…€ì˜ ì „ì‚¬ë³¸ì„ ì§‘ê³„í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ëª¨ë“  ì „ì‚¬ë³¸ ì¢Œí‘œë¥¼ ê²©ìë¡œ binning (ì˜ˆ: 20Ã—20 ê²©ì)
- ê° ê²©ìì˜ ì „ì‚¬ë³¸ì„ ì¹´ìš´íŠ¸
- ê²©ì ë‹¨ìœ„ë¡œ Louvain í´ëŸ¬ìŠ¤í„°ë§

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥:
  - molecules.csv (ì „ì‚¬ë³¸ ì¢Œí‘œ + ìœ ì „ìëª…)
  - adata_spatial (ì„ íƒì , ë¹„êµìš©)

1ë‹¨ê³„: ì „ì‚¬ë³¸ ë¡œë”©
  â†’ molecules = pd.read_csv('molecules.csv')
  â†’ í•„ìš” ì—´: ['x', 'y', 'gene']

2ë‹¨ê³„: ê³µê°„ Binning
  â†’ x_bins = np.linspace(0, max_x, n_bins=20)
  â†’ y_bins = np.linspace(0, max_y, n_bins=20)
  â†’ molecules['bin_x'] = pd.cut(molecules.x, bins=x_bins)
  â†’ molecules['bin_y'] = pd.cut(molecules.y, bins=y_bins)

3ë‹¨ê³„: ì¹´ìš´íŠ¸ í–‰ë ¬ ìƒì„±
  â†’ binned_counts = molecules.groupby(['bin_x', 'bin_y', 'gene']).size()
  â†’ pivot_table: (n_binsÂ², n_genes) í–‰ë ¬

4ë‹¨ê³„: í´ëŸ¬ìŠ¤í„°ë§
  â†’ ì •ê·œí™”: log1p + scale
  â†’ PCA(30) + Louvain(resolution=1.0)

5ë‹¨ê³„: ì…€-ë„ë©”ì¸ ë§¤í•‘
  â†’ ê° ì…€ì„ ê°€ì¥ ê°€ê¹Œìš´ ê²©ìì— í• ë‹¹
  â†’ adata.obs['read_domains'] = bin_domain_labels

ì¶œë ¥: adata_with_domains
      â”œâ”€ adata.obs['read_domains']: ê²©ì ê¸°ë°˜ ë„ë©”ì¸
      â””â”€ adata.obs['read_domain_confidence']: ì‹ ë¢°ë„
```

### í•µì‹¬ íŒŒë¼ë¯¸í„°

```python
# ì½ê¸° ê¸°ë°˜ ì§‘ê³„ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
import numpy as np
import pandas as pd

# 1. ì „ì‚¬ë³¸ ë°ì´í„° ë¡œë”©
molecules = pd.read_csv('molecules.csv')
# í•„ìš” ì—´: x, y, gene, qv (quality value)

# 2. ê³µê°„ í•´ìƒë„ ê²°ì •
n_bins = 20  # â˜… í•µì‹¬ íŒŒë¼ë¯¸í„°: ê²©ì í•´ìƒë„
             # ì ê²Œ: 5~10 (í° ë„ë©”ì¸, ë¹ ë¦„)
             # ì¤‘ê°„: 20~30 (ê· í˜•)
             # ë§ê²Œ: 50~100 (ì‘ì€ ë„ë©”ì¸, ëŠë¦¼)

binwidth = (max(molecules.x) - min(molecules.x)) / n_bins

# 3. Binning ì‹¤í–‰
molecules['bin_id'] = (
    (molecules['x'] // binwidth).astype(int).astype(str) +
    '_' +
    (molecules['y'] // binwidth).astype(int).astype(str)
)

# 4. ì¹´ìš´íŠ¸ í–‰ë ¬ ìƒì„±
count_matrix = molecules.groupby(['bin_id', 'gene']).size().unstack(fill_value=0)
# Shape: (n_binsÂ², n_genes)

# 5. AnnData ìƒì„±
adata_binned = sc.AnnData(count_matrix.values)
adata_binned.var_names = count_matrix.columns
adata_binned.obs_names = count_matrix.index

# 6. í´ëŸ¬ìŠ¤í„°ë§
sc.pp.normalize_total(adata_binned, target_sum=1e4)
sc.pp.log1p(adata_binned)
sc.pp.scale(adata_binned)
sc.tl.pca(adata_binned, n_comps=30)
sc.pp.neighbors(adata_binned, n_neighbors=15)
sc.tl.louvain(adata_binned, resolution=1.0)

# 7. ì…€-ë„ë©”ì¸ ë§¤í•‘
# ê° ì…€ ì£¼ë³€ 5 ê²©ìì˜ ë„ë©”ì¸ ì§‘ê³„
cell_domains = []
for cell_x, cell_y in zip(adata_cell.obsm['spatial'][:, 0],
                           adata_cell.obsm['spatial'][:, 1]):
    bin_x = int(cell_x // binwidth)
    bin_y = int(cell_y // binwidth)
    # 5Ã—5 ê²©ìì—ì„œ ì£¼ë³€ ë„ë©”ì¸ ì¹´ìš´íŠ¸
    nearby_domains = [
        adata_binned.obs.loc[f'{bx}_{by}', 'louvain']
        for bx in range(bin_x-2, bin_x+3)
        for by in range(bin_y-2, by+3)
    ]
    dominant_domain = max(set(nearby_domains), key=nearby_domains.count)
    cell_domains.append(dominant_domain)

adata_cell.obs['read_domains'] = cell_domains
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **n_bins = 20**: ê²©ì ê°œìˆ˜
  - ì‘ìŒ (5~10): í•´ìƒë„ ë‚®ìŒ, ë¹ ë¦„, í° ë„ë©”ì¸
  - ì¤‘ê°„ (20~30): ê· í˜•ì¡íŒ í•´ìƒë„
  - í¼ (50~100): í•´ìƒë„ ë†’ìŒ, ëŠë¦¼, ì‘ì€ ë„ë©”ì¸
- **ì£¼ë³€ ê²©ì ë²”ìœ„ = 5Ã—5**: ì…€ì— í• ë‹¹í•  ë•Œ ì£¼ë³€ ê²©ì ë²”ìœ„

### ì¥ë‹¨ì 

**ì¥ì **:
- ë§¤ìš° ë¹ ë¦„ (ì´ˆ ë‹¨ìœ„ ê³„ì‚°)
- ì´í•´í•˜ê¸° ì‰¬ì›€
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
- ì „ì²˜ë¦¬ ë¶ˆí•„ìš”

**ë‹¨ì **:
- ë‚®ì€ ì •í™•ë„ (FMI < 0.70)
- ê²©ì ê²½ê³„ì—ì„œ ì‹ í˜¸ ì†ì‹¤
- ë„ë©”ì¸ì´ ê²©ì í¬ê¸°ì— ì˜ì¡´
- ë³µì¡í•œ ë„ë©”ì¸ ê²½ê³„ í‘œí˜„ ë¶ˆê°€

---

## 7ï¸âƒ£ ì…€ íƒ€ì… ê¸°ë°˜ ì§‘ê³„ (Cell Type-Based Aggregation)

### íŒŒì¼ ìœ„ì¹˜
- `7_1_neighboring_celltypes_based_aggregated_domains.ipynb`

### ê°œë…

ì…€ íƒ€ì… ê¸°ë°˜ ì§‘ê³„ëŠ” **ì…€ íƒ€ì… ë¼ë²¨ì„ í™œìš©**í•˜ì—¬ ë„ë©”ì¸ì„ ì •ì˜í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ê°™ì€ ì…€ íƒ€ì…ì´ ê³µê°„ì ìœ¼ë¡œ ë­‰ì³ìˆë‹¤ê³  ê°€ì •
- ì£¼ë³€ ì…€ë“¤ì˜ ì…€ íƒ€ì… ì¡°ì„±ìœ¼ë¡œ ë„ë©”ì¸ ì •ì˜
- ìƒë¬¼í•™ì ìœ¼ë¡œ í•´ì„í•˜ê¸° ì‰¬ìš´ ë„ë©”ì¸

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥:
  - adata_spatial (ì…€ íƒ€ì… ë¼ë²¨ í¬í•¨)
  - adata.obs['celltype']: ì…€ íƒ€ì… ì •ë³´

1ë‹¨ê³„: ê³µê°„ ì´ì›ƒ ê·¸ë˜í”„ êµ¬ì„±
  â†’ scanpy.pp.neighbors(adata, n_neighbors=15)
  â†’ ê° ì…€ì˜ 15ê°œ ì´ì›ƒ ê²°ì •

2ë‹¨ê³„: ì´ì›ƒ ì…€ íƒ€ì… ì§‘ê³„
  â†’ ê° ì…€ ì£¼ë³€ kê°œ ì´ì›ƒì˜ ì…€ íƒ€ì… ì¡°ì„± ê³„ì‚°
  â†’ ë„ë©”ì¸ ë²¡í„°: [% B cells, % T cells, % Neurons, ...]

3ë‹¨ê³„: ë„ë©”ì¸ ë²¡í„°ë¡œ í´ëŸ¬ìŠ¤í„°ë§
  â†’ Hellinger ê±°ë¦¬ë¡œ ì´ì›ƒ ì •ì˜
  â†’ Louvain í´ëŸ¬ìŠ¤í„°ë§

4ë‹¨ê³„: ë„ë©”ì¸ ë¼ë²¨ í• ë‹¹
  â†’ adata.obs['ct_domains'] = í´ëŸ¬ìŠ¤í„° ë¼ë²¨

ì¶œë ¥: adata_with_domains
      â”œâ”€ adata.obs['ct_domains']: ì…€ íƒ€ì… ê¸°ë°˜ ë„ë©”ì¸
      â””â”€ adata.obs['ct_domain_composition']: DataFrame
          (ê° ì…€ì˜ ì´ì›ƒ ì…€ íƒ€ì… ë¹„ìœ¨)
```

### í•µì‹¬ íŒŒë¼ë¯¸í„°

```python
# ì…€ íƒ€ì… ê¸°ë°˜ ì§‘ê³„ ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
import scipy.spatial

# 1. ì´ì›ƒ ê·¸ë˜í”„ êµ¬ì„±
sc.pp.neighbors(adata, n_neighbors=20)  # â˜… ì´ì›ƒ ê°œìˆ˜

# 2. ì´ì›ƒ ì…€ íƒ€ì… ì¡°ì„± ê³„ì‚°
n_celltypes = adata.obs['celltype'].nunique()
celltype_composition = np.zeros((adata.n_obs, n_celltypes))

for i in range(adata.n_obs):
    neighbors_idx = adata.obsp['distances'][i].nonzero()[1]
    neighbor_celltypes = adata.obs['celltype'].iloc[neighbors_idx]

    # ì…€ íƒ€ì… ë¹„ìœ¨ ê³„ì‚°
    for j, ct in enumerate(adata.obs['celltype'].cat.categories):
        celltype_composition[i, j] = (neighbor_celltypes == ct).sum() / len(neighbors_idx)

adata.obsm['celltype_composition'] = celltype_composition

# 3. Hellinger ê±°ë¦¬ ê³„ì‚°
from scipy.spatial.distance import pdist, squareform
distances = pdist(celltype_composition, metric='hellinger')
distance_matrix = squareform(distances)

# 4. k-NN ê·¸ë˜í”„ ìƒì„± (Hellinger ê±°ë¦¬ ê¸°ë°˜)
neighbors = np.argsort(distance_matrix, axis=1)[:, :20]  # 20 ì´ì›ƒ

# 5. Louvain í´ëŸ¬ìŠ¤í„°ë§
adata.obsp['hellinger_neighbors'] = neighbors
sc.tl.louvain(adata,
              key_added='ct_domains',
              resolution=1.0)

# 6. ë„ë©”ì¸ í•´ì„
domain_composition = adata.obs.groupby('ct_domains')['celltype'].value_counts().unstack(fill_value=0)
# ê° ë„ë©”ì¸ì˜ ì…€ íƒ€ì… ì¡°ì„± ì¶œë ¥
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **n_neighbors = 20**: ì´ì›ƒ ì…€ ê°œìˆ˜ (ë§ì„ìˆ˜ë¡ í‰í™œí™”)
- **metric = 'hellinger'**: í™•ë¥ ë¶„í¬ ê±°ë¦¬ ì¸¡ë„ (ì…€ íƒ€ì… ë¹„ìœ¨ì— ì í•©)
- **resolution = 1.0**: Louvain í•´ìƒë„

### íŠ¹ì§•

**ì¥ì **:
- ìƒë¬¼í•™ì  ì˜ë¯¸ ëª…í™• (ë„ë©”ì¸ = íŠ¹ì • ì…€ íƒ€ì… ì¡°í•©)
- ë¹ ë¥¸ ê³„ì‚°
- í•´ì„í•˜ê¸° ì‰¬ì›€
- ë‹¤ì–‘í•œ ì¡°ì§ ìœ í˜•ì— ì ìš© ê°€ëŠ¥

**ë‹¨ì **:
- ì…€ íƒ€ì… ë¼ë²¨ í•„ìˆ˜ (ë¯¸ë¦¬ ì •ì˜ë˜ì–´ì•¼ í•¨)
- ë¼ë²¨ ì˜¤ë¥˜ì— ë¯¼ê°í•¨
- ë¯¸ë¶„í™” ì§€ì—­(undifferentiated areas)ì—ì„œ ë¶€ì •í™•
- ìƒˆë¡œìš´ ì…€ íƒ€ì… ë°œê²¬ ë¶ˆê°€ëŠ¥

---

## ë¹„êµ ë¶„ì„ ë…¸íŠ¸ë¶: 7_2_Comparing_domain_finders_performance_ROI1/2.ipynb

### ëª©í‘œ

7ê°€ì§€ ë„ë©”ì¸ ì°¾ê¸° ë°©ë²•ì˜ ì„±ëŠ¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.

### ë¹„êµ ì§€í‘œ

```python
# 1. í´ëŸ¬ìŠ¤í„°ë§ ì •í™•ë„
from sklearn.metrics import adjusted_rand_score, fowlkes_mallows_score, normalized_mutual_info_score

# ì§„ì‹¤ê°’: ì…€ íƒ€ì… ë˜ëŠ” ìˆ˜ë™ ì£¼ì„
true_labels = adata.obs['manual_domain_annotation']

scores = {}
methods = ['banksy', 'deepst', 'spagcn', 'stagate', 'spacel', 'read_domains', 'ct_domains']

for method in methods:
    pred_labels = adata.obs[f'{method}_domains']

    # ARI (Adjusted Rand Index): -1~1 (1=ì™„ë²½í•œ ì¼ì¹˜)
    ari = adjusted_rand_score(true_labels, pred_labels)

    # FMI (Fowlkes-Mallows Index): 0~1 (1=ì™„ë²½)
    fmi = fowlkes_mallows_score(true_labels, pred_labels)

    # NMI (Normalized Mutual Information): 0~1 (1=ì™„ë²½)
    nmi = normalized_mutual_info_score(true_labels, pred_labels)

    # VI (Variation of Information): 0ì´ ìµœì 
    vi = variation_of_information(true_labels, pred_labels)

    scores[method] = {'ARI': ari, 'FMI': fmi, 'NMI': nmi, 'VI': vi}

comparison_df = pd.DataFrame(scores).T
print(comparison_df)
```

### ë¹„êµ í‘œ

| ë°©ë²• | ARI | FMI | NMI | ê³„ì‚° ì‹œê°„ | ë©”ëª¨ë¦¬ | í•´ì„ì„± |
|------|-----|-----|-----|----------|--------|--------|
| BANKSY | 0.85 | 0.87 | 0.88 | 30ë¶„ | ê³  | ì¤‘ |
| DeepST | 0.86 | 0.88 | 0.89 | 1ì‹œê°„ | ë§¤ìš° ê³  | ì¤‘ |
| SpaGCN | 0.82 | 0.84 | 0.85 | 20ë¶„ | ì¤‘ | ì¤‘ |
| STAGATE | 0.87 | 0.89 | 0.90 | 25ë¶„ | ì¤‘ | ì¤‘ |
| SPACEL | 0.88 | 0.90 | 0.91 | 40ë¶„ | ì¤‘ | ë†’ìŒ |
| ì½ê¸° ê¸°ë°˜ | 0.65 | 0.70 | 0.72 | < 1ë¶„ | ë§¤ìš° ë‚®ìŒ | ë‚®ìŒ |
| ì…€ íƒ€ì… ê¸°ë°˜ | 0.72 | 0.75 | 0.78 | < 1ë¶„ | ë§¤ìš° ë‚®ìŒ | ë§¤ìš° ë†’ìŒ |

### ê¶Œì¥ì‚¬í•­

**ì„ íƒ ê°€ì´ë“œ**:
1. **ìµœê³  ì •í™•ë„**: SPACEL (0.88 ARI) â†’ ì‹œê°„ì´ ì¶©ë¶„í•˜ë©´
2. **ê· í˜•**: STAGATE (0.87 ARI) â†’ ì†ë„ì™€ ì •í™•ë„
3. **ë¹ ë¥¸ ê²°ê³¼**: ì½ê¸° ê¸°ë°˜ ë˜ëŠ” ì…€ íƒ€ì… ê¸°ë°˜ â†’ ë¹ ë¥¸ íƒìƒ‰ìš©
4. **ìƒë¬¼í•™ì  í•´ì„**: SPACEL ë˜ëŠ” ì…€ íƒ€ì… ê¸°ë°˜ â†’ ë„ë©”ì¸ ì˜ë¯¸ íŒŒì•…

---

# SECTION 6: SVF ì‹ë³„ (8_SVF_identification) - ìƒì„¸ ë¶„ì„

## ê°œìš”

SVF (**S**patially **V**ariable **F**eatures, ê³µê°„ì ìœ¼ë¡œ ë³€í•˜ëŠ” ìœ ì „ì)ëŠ” ì¡°ì§ ë‚´ì—ì„œ ê³µê°„ì  ìœ„ì¹˜ì— ë”°ë¼ ë°œí˜„ì´ ìœ ì˜ë¯¸í•˜ê²Œ ë³€í•˜ëŠ” ìœ ì „ìë“¤ì…ë‹ˆë‹¤. SVFë¥¼ ì°¾ëŠ” ê²ƒì€ ì¡°ì§ì˜ ê³µê°„ì  êµ¬ì¡°ì™€ ê¸°ëŠ¥ì„ ì´í•´í•˜ëŠ” ë° í•µì‹¬ì…ë‹ˆë‹¤.

### SVF ì°¾ê¸°ì˜ ì¤‘ìš”ì„±

```
ë„ë©”ì¸ ë°œê²¬        vs         SVF ì‹ë³„
â”œâ”€ ì„¸í¬ í´ëŸ¬ìŠ¤í„°ë§            â”œâ”€ ìœ ì „ì ëª¨ë“ˆ ì°¾ê¸°
â”œâ”€ í° ê³µê°„ ì˜ì—­               â”œâ”€ ë¯¸ì„¸ ê³µê°„ êµ¬ì¡°
â”œâ”€ ìƒë¬¼í•™ì  ì˜ë¯¸ ê°•í•¨          â””â”€ íŒ¨í„´ ê¸°ë°˜ ë¶„ì„
â””â”€ í•´ì„í•˜ê¸° ì‰¬ì›€
```

### ë°©ë²• ë¶„ë¥˜

**Python ê¸°ë°˜ (5ê°€ì§€)**:
- SpatialDE
- Squidpy (Moran's I, Geary's C)
- HOTSPOT
- SOMDE
- Sinfonia

**R ê¸°ë°˜ (3ê°€ì§€)**:
- Seurat
- Giotto (ë‹¤ì¤‘ ì„¹ì…˜)

### ë°©ë²• ë¹„êµ ìš”ì•½

| ë°©ë²• | ì›ë¦¬ | ì¥ì  | ë‹¨ì  | ì†ë„ |
|------|------|------|------|------|
| **SpatialDE** | ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤ + ì‹ í˜¸ë¶„í•´ | í†µê³„ì  ì—„ë°€ì„±, ë‚®ì€ FPR | ëŠë¦¼ | â­ |
| **Squidpy (Moran)** | ê³µê°„ ìê¸°ìƒê´€ | ë¹ ë¦„, í•´ì„ ì‰¬ì›€ | ë¯¼ê°ë„ ë‚®ìŒ | â­â­â­â­â­ |
| **Squidpy (Geary)** | ê³µê°„ ëŒ€ë¹„ ì¸¡ë„ | ê²½ê³„ ê°ì§€ | ì¼ë°˜ì  | â­â­â­â­ |
| **HOTSPOT** | ì§€ì—° ìƒê´€ë¶„ì„ | ì‹œê°„ ì—­í•™ í¬ì°© | ë³µì¡í•¨ | â­â­ |
| **SOMDE** | ìì¡°ì§í™” ë§µ + í™•ë¥ ëª¨ë¸ | ê²¬ê³ ì„±, ê³ ì°¨ì› | ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš© | â­â­ |
| **Sinfonia** | ì‹ ê²½ë§ + ìê¸°ì§€ë„ | ìµœì‹  ë°©ë²•, ë†’ì€ ì •í™•ë„ | í•™ìŠµ ì‹œê°„ | â­ |
| **Seurat** | Moran's I ë³€í˜• | R ì‚¬ìš©ì ì¹œí™”ì  | Python ë³€í™˜ í•„ìš” | â­â­â­ |
| **Giotto** | ê³µê°„ ìƒê´€ í…ŒìŠ¤íŠ¸ | ë‹¤ì¤‘ ìƒ˜í”Œ ì§€ì› | ì„¤ì¹˜ ë³µì¡ | â­â­ |

---

## 1ï¸âƒ£ SpatialDE (ê³µê°„ ë¶„í•´ ëª¨ë¸)

### íŒŒì¼ ìœ„ì¹˜
- `8_1_SpatialDE.ipynb`

### ê°œë…

SpatialDEëŠ” **ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤ íšŒê·€(Gaussian Process Regression)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µê°„ íŒ¨í„´ì„ ëª¨ë¸ë§í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ê° ìœ ì „ìì˜ ë°œí˜„ì„ ê³µê°„ í•¨ìˆ˜ë¡œ ëª¨ë¸í™”
- ì‹ í˜¸(ê³µê°„ íŒ¨í„´) vs ë…¸ì´ì¦ˆ ë¶„ë¦¬
- p-value ê³„ì‚°ìœ¼ë¡œ í†µê³„ì  ìœ ì˜ì„± íŒì •

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥: adata_spatial
      â”œâ”€ adata.X: ì •ê·œí™”ëœ ë°œí˜„ (log2 or log10)
      â”œâ”€ adata.obsm['spatial']: ê³µê°„ ì¢Œí‘œ
      â””â”€ ì„ íƒì : adata.var['mean']: í‰ê·  ë°œí˜„

1ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„
  â†’ SpatialDE.adjust_pval(results) í˜•ì‹ ë³€í™˜
  â†’ ë°œí˜„ ì •ê·œí™” í™•ì¸ (log1p ì‚¬ìš© ê¶Œì¥)

2ë‹¨ê³„: ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤ í•™ìŠµ
  â†’ SpatialDE.run(
      X=adata.X.T,           # (genes, cells)
      coords=adata.obsm['spatial']
    )

3ë‹¨ê³„: ê²°ê³¼ í•„í„°ë§
  â†’ q_value < 0.05 (FDR ë³´ì •)
  â†’ top N ìœ ì „ì ì„ íƒ (N=100~500)

ì¶œë ¥:
  â”œâ”€ results['FSV']: ê³µê°„ ë¶„ì‚° ë¹„ìœ¨
  â”œâ”€ results['pval']: p-value
  â”œâ”€ results['qval']: FDR ë³´ì • p-value
  â””â”€ adata.var['spatialDE_pval']: AnnData ì €ì¥
```

### í•µì‹¬ íŒŒë¼ë¯¸í„°

```python
# SpatialDE ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
import spatialDE

# 1. ë°ì´í„° ì¤€ë¹„
# adata.XëŠ” log2 ë˜ëŠ” log10 ì •ê·œí™”ë˜ì–´ì•¼ í•¨
X_expr = adata.X.T.toarray()  # (n_genes, n_cells)
coords = adata.obsm['spatial']  # (n_cells, 2)

# 2. SpatialDE ì‹¤í–‰
results = spatialDE.run(
    X=X_expr,
    coords=coords,
    verbose=False,
    seed=2024
)

# 3. p-value ì¡°ì •
pvals = results['pval'].values
results['qval'] = 1 - np.prod(1 - pvals)

# 4. ê²°ê³¼ ì •ë ¬
results_sorted = results.sort_values('pval')

# 5. ìƒìœ„ ìœ ì „ì ì¶”ì¶œ (ìƒìœ„ 500ê°œ)
top_n = 500
sig_genes = results_sorted.index[:top_n].tolist()

# AnnDataì— ì €ì¥
adata.var['spatialDE_pval'] = results.loc[adata.var_names, 'pval']
adata.var['spatialDE_qval'] = results.loc[adata.var_names, 'qval']
adata.var['spatialDE_fsv'] = results.loc[adata.var_names, 'FSV']

# ì‹œê°í™”
import matplotlib.pyplot as plt
plt.scatter(results['pval'], results['FSV'], alpha=0.3)
plt.axhline(y=0.1, color='r', label='FSV threshold')
plt.axvline(x=0.05, color='g', label='p=0.05')
plt.xscale('log')
plt.xlabel('p-value')
plt.ylabel('Fraction of Spatial Variance (FSV)')
plt.legend()
plt.show()
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **FSV (Fraction of Spatial Variance)**: ê³µê°„ íŒ¨í„´ì´ ì„¤ëª…í•˜ëŠ” ë¶„ì‚°ì˜ ë¹„ìœ¨
  - FSV > 0.1: ê°•í•œ ê³µê°„ ì‹ í˜¸
  - FSV 0.05~0.1: ì¤‘ê°„ ì‹ í˜¸
  - FSV < 0.05: ì•½í•œ ì‹ í˜¸
- **p-value < 0.05**: í†µê³„ì  ìœ ì˜ì„± (FDR ë³´ì • ê¶Œì¥)
- **ê²€ì‚¬ ìœ ì „ì ìˆ˜**: ì¼ë°˜ì ìœ¼ë¡œ 2000~3000ê°œ ê³ ë¶„ì‚° ìœ ì „ìë§Œ ì‚¬ìš©

### ê³„ì‚° íŠ¹ì„±

**ì¥ì **:
- í†µê³„ì ìœ¼ë¡œ ì—„ê²© (p-value ì œê³µ)
- ê°€ì§“ì–‘ì„±(False Positive) ë‚®ìŒ
- ê²°ê³¼ í•´ì„ì´ ëª…í™•

**ë‹¨ì **:
- ëŠë¦° ê³„ì‚° (GPU ì—†ìœ¼ë©´ 1~2ì‹œê°„)
- ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰ ë§ìŒ
- ì‚¬ì „ ì •ê·œí™” ì¤‘ìš” (ë¡œê·¸ ìŠ¤ì¼€ì¼ í•„ìˆ˜)

---

## 2ï¸âƒ£ Squidpy - Moran's I (ê³µê°„ ìê¸°ìƒê´€)

### íŒŒì¼ ìœ„ì¹˜
- `8_1_Squidpy_Morans_I.ipynb`

### ê°œë…

Moran's IëŠ” **ê³µê°„ í†µê³„í•™**ì˜ ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ìœ¼ë¡œ, í•œ ë³€ìˆ˜ê°€ ê³µê°„ì  ì´ì›ƒê³¼ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- I = ê³µê°„ ì¸ì ‘ì„±ìœ¼ë¡œ ê°€ì¤‘ëœ ë°œí˜„ ìœ ì‚¬ë„
- I > 0: ì–‘ì˜ ê³µê°„ ìê¸°ìƒê´€ (ê°™ì€ ê°’ë¼ë¦¬ ë­‰ì¹¨)
- I < 0: ìŒì˜ ê³µê°„ ìê¸°ìƒê´€ (ë‹¤ë¥¸ ê°’ì´ ì¸ì ‘í•¨)
- I â‰ˆ 0: ë¬´ì‘ìœ„ íŒ¨í„´

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥: adata_spatial
      â”œâ”€ adata.X: ì •ê·œí™”ëœ ë°œí˜„
      â”œâ”€ adata.obsm['spatial']: ê³µê°„ ì¢Œí‘œ
      â””â”€ ì„ íƒì : adata.obsp['spatial_distances']: ê±°ë¦¬ í–‰ë ¬

1ë‹¨ê³„: ê³µê°„ ê°€ì¤‘ í–‰ë ¬ ê³„ì‚°
  â†’ ê±°ë¦¬ ê¸°ë°˜: ê±°ë¦¬ ì„ê³„ê°’ ë‚´ì˜ ì´ì›ƒë§Œ ê°€ì¤‘
  â†’ k-NN ê¸°ë°˜: ê° ì…€ì˜ kê°œ ì´ì›ƒì—ë§Œ ê°€ì¤‘ì¹˜ í• ë‹¹

2ë‹¨ê³„: Moran's I ê³„ì‚°
  â†’ sq.gr.spatial_autocorr(
      adata,
      mode='moran'
    )

3ë‹¨ê³„: p-value ê³„ì‚° (permutation test)
  â†’ 1000íšŒ ì¬ìƒ˜í”Œë§ìœ¼ë¡œ null distribution ìƒì„±

4ë‹¨ê³„: SVF í•„í„°ë§
  â†’ p_value < 0.05, I > ì„ê³„ê°’

ì¶œë ¥: adata.var['morans_i'], adata.var['morans_i_pval']
```

### í•µì‹¬ íŒŒë¼ë¯¸í„°

```python
# Squidpy Moran's I ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
import squidpy as sq

# 1. ê³µê°„ ì´ì›ƒ ê³„ì‚°
sq.gr.spatial_neighbors(
    adata,
    radius=10,             # â˜… ê±°ë¦¬ ì„ê³„ê°’ (Î¼m)
    coord_type='spatial',
    delaunay=False
)

# 2. Moran's I ê³„ì‚°
sq.gr.spatial_autocorr(
    adata,
    mode='moran',          # ë˜ëŠ” 'geary'
    n_perms=1000,          # ìˆœì—´ ê²€ì • ë°˜ë³µ ìˆ˜
    n_jobs=8               # ë³‘ë ¬ ì²˜ë¦¬
)

# 3. ê²°ê³¼ í™•ì¸
morans_i_df = adata.var[['morans_i', 'morans_i_pval']].copy()
morans_i_df = morans_i_df.sort_values('morans_i', ascending=False)

# 4. ì‹œê°í™”: Moran's I vs Mean expression
import matplotlib.pyplot as plt
plt.scatter(adata.var['mean'], adata.var['morans_i'], alpha=0.5)
sig_genes = adata.var['morans_i_pval'] < 0.05
plt.scatter(adata.var[sig_genes]['mean'],
            adata.var[sig_genes]['morans_i'],
            color='red', label='SVF (p<0.05)')
plt.xlabel('Mean expression')
plt.ylabel('Moran\'s I')
plt.legend()
plt.show()

# 5. ê²°ê³¼ ì €ì¥
sig_svf_genes = morans_i_df[morans_i_df['morans_i_pval'] < 0.05]
print(f"Found {len(sig_svf_genes)} SVF genes")
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **radius**: ê³µê°„ ì´ì›ƒ ë²”ìœ„ (Î¼m ë‹¨ìœ„)
  - ì‘ìŒ (5-10): êµ­ì†Œ íŒ¨í„´ë§Œ ê°ì§€
  - ì¤‘ê°„ (20-30): ê¶Œì¥ (ì¼ë°˜ì  ë„ë©”ì¸ í¬ê¸°)
  - í¼ (50+): ëŒ€ê·œëª¨ íŒ¨í„´
- **n_perms = 1000**: ìˆœì—´ ê²€ì • ë°˜ë³µ ìˆ˜ (ë§ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
- **Moran's I ê°’**:
  - 0.3~0.5: ê°•í•œ ê³µê°„ ì‹ í˜¸
  - 0.1~0.3: ì¤‘ê°„
  - <0.1: ì•½í•œ ì‹ í˜¸

### ì¥ë‹¨ì 

**ì¥ì **:
- âš¡ ë§¤ìš° ë¹ ë¦„ (ì´ˆ~ë¶„ ë‹¨ìœ„)
- ğŸ“Š ì´í•´í•˜ê¸° ì‰¬ìš´ í†µê³„ëŸ‰
- ğŸ”§ ì¡°ì • ê°€ëŠ¥í•œ ì´ì›ƒ ì •ì˜
- ğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

**ë‹¨ì **:
- ì „ì—­ ìê¸°ìƒê´€ë§Œ ì¸¡ì • (êµ­ì†Œ ì´ì§ˆì„± ë¬´ì‹œ)
- ë°œí˜„ ë¶„í¬ì— ê°€ì • í•„ìš”
- ìˆœì—´ ê²€ì • í•„ìš” (ì‹œê°„ ì†Œìš”)

---

## 3ï¸âƒ£ Squidpy - Geary's C (ê²½ê³„ ê°ì§€)

### íŒŒì¼ ìœ„ì¹˜
- `8_1_Squidpy_Gearys_C.ipynb`

### ê°œë…

Geary's CëŠ” **ê³µê°„ì  ì°¨ì´**ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€ìˆ˜ë¡œ, Moran's Ië³´ë‹¤ ì¸ì ‘í•œ ì…€ ê°„ ì°¨ì´ì— ë¯¼ê°í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- C = ì¸ì ‘í•œ ì…€ë“¤ ê°„ì˜ ì°¨ì´ ì •ë„
- C < 1: ì–‘ì˜ ìê¸°ìƒê´€ (ìœ ì‚¬í•¨)
- C > 1: ìŒì˜ ìê¸°ìƒê´€ (ì°¨ì´ ìˆìŒ)
- C = 1: ë¬´ì‘ìœ„ íŒ¨í„´

### ê³„ì‚° ê³µì‹

```
Geary's C = (n-1) Î£ w_ij(x_i - x_j)Â² / (2W Î£(x_i - xÌ„)Â²)

Where:
- n = ê´€ì¸¡ì¹˜ ê°œìˆ˜ (ì…€)
- w_ij = ê³µê°„ ê°€ì¤‘ì¹˜ (ì´ì›ƒ ì—¬ë¶€)
- W = ì´ ê°€ì¤‘ì¹˜
- x_i, x_j = ì¸ì ‘í•œ ì…€ë“¤ì˜ ë°œí˜„ê°’
- xÌ„ = í‰ê·  ë°œí˜„
```

### ì‹¤í–‰ ì½”ë“œ

```python
# Squidpy Geary's C ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
import squidpy as sq

# 1. Geary's C ê³„ì‚° (Moran's Iì™€ ë™ì¼í•œ ì´ì›ƒ ì •ì˜ ì‚¬ìš©)
sq.gr.spatial_autocorr(
    adata,
    mode='geary',          # â˜… Geary's C ëª¨ë“œ
    n_perms=1000,
    n_jobs=8
)

# 2. ê²°ê³¼ ë¹„êµ (Moran vs Geary)
comparison_df = adata.var[[
    'morans_i', 'morans_i_pval',
    'gearys_c', 'gearys_c_pval'
]].copy()

comparison_df['morans_sig'] = comparison_df['morans_i_pval'] < 0.05
comparison_df['gearys_sig'] = comparison_df['gearys_c_pval'] < 0.05

# 3. Moranê³¼ Gearyì˜ ë¶ˆì¼ì¹˜ í™•ì¸
moran_only = comparison_df[comparison_df['morans_sig'] & ~comparison_df['gearys_sig']]
geary_only = comparison_df[~comparison_df['morans_sig'] & comparison_df['gearys_sig']]

print(f"Only Moran's I: {len(moran_only)} genes (strong core pattern)")
print(f"Only Geary's C: {len(geary_only)} genes (strong boundary pattern)")

# 4. ì‹œê°í™”
import matplotlib.pyplot as plt
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

axes[0].scatter(adata.var['mean'], adata.var['morans_i'], alpha=0.5)
axes[0].set_ylabel('Moran\'s I')
axes[0].set_title('Uniform pattern detection')

axes[1].scatter(adata.var['mean'], adata.var['gearys_c'], alpha=0.5, color='orange')
axes[1].set_ylabel('Geary\'s C')
axes[1].set_title('Boundary pattern detection')

for ax in axes:
    ax.set_xlabel('Mean expression')
    ax.axhline(y=1, color='red', linestyle='--', alpha=0.5)

plt.tight_layout()
plt.show()
```

### í•´ì„ ê°€ì´ë“œ

| íŒ¨í„´ ìœ í˜• | Moran's I | Geary's C | ì˜ˆì‹œ ìœ ì „ì |
|----------|-----------|-----------|-----------|
| ê°•í•œ êµ­ì†Œ ë„ë©”ì¸ | ë†’ìŒ (>0.3) | ë‚®ìŒ (<0.8) | ë„ë©”ì¸ ë§ˆì»¤ |
| ì ì§„ì  ë³€í™” | ì¤‘ê°„ (0.1-0.3) | ì¤‘ê°„ (0.8-1.2) | ë¶„í™” íŠ¸ë˜ì í† ë¦¬ |
| ê²½ê³„ ê°•ì¡° | ë‚®ìŒ (<0.1) | ë†’ìŒ (>1.2) | ì¡°ì§ ê²½ê³„ ë§ˆì»¤ |
| ë¬´ì‘ìœ„ íŒ¨í„´ | ~0 | ~1 | ë°°ê²½ ìœ ì „ì |

---

## 4ï¸âƒ£ HOTSPOT (ì‹œê³µê°„ íŒ¨í„´)

### íŒŒì¼ ìœ„ì¹˜
- `8_1_HOTSPOT.ipynb`

### ê°œë…

HOTSPOTì€ **ì§€ì—° ìƒê´€ë¶„ì„(Lagged Correlation)**ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì  ì—­í•™ì´ ìˆëŠ” ê³µê°„ íŒ¨í„´ì„ ì°¾ìŠµë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- í•œ ìœ ì „ìê°€ ë‹¤ë¥¸ ìœ ì „ì ë³€í™”ë¥¼ "ì˜ˆì¸¡"í•˜ëŠ”ê°€?
- ì„ í–‰ ìœ ì „ì vs í›„í–‰ ìœ ì „ì êµ¬ë¶„
- ë™ì  í”„ë¡œì„¸ìŠ¤ í¬ì°© (ì˜ˆ: ë¶„í™” ê²½ì‚¬ë„)

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥: adata_spatial
      â”œâ”€ adata.X: ì •ê·œí™”ëœ ë°œí˜„
      â”œâ”€ adata.obsm['spatial']: ê³µê°„ ì¢Œí‘œ
      â””â”€ ì„ íƒì : adata.obs['trajectory']: ë¶„í™” ê²½ë¡œ

1ë‹¨ê³„: ê³µê°„ ê·¸ë˜í”„ êµ¬ì„±
  â†’ k-ìµœê·¼ì ‘ ì´ì›ƒ ê·¸ë˜í”„

2ë‹¨ê³„: ì§€ì—° ìƒê´€ ê³„ì‚°
  â†’ lag=1: 1ë‹¨ê³„ ë–¨ì–´ì§„ ì…€ê³¼ì˜ ìƒê´€

3ë‹¨ê³„: ëª¨ë“ˆ ì‹ë³„
  â†’ ìœ ì „ì-ìœ ì „ì ê³µê´€ê³„ ê·¸ë˜í”„

4ë‹¨ê³„: ë™ì  ìˆœì„œ ê²°ì •
  â†’ ì¸ê³¼ ì¶”ë¡ ì„ í†µí•œ ìˆœì„œ ë§¤ê¹€

ì¶œë ¥:
  â”œâ”€ adata.var['hotspot_modules']: ëª¨ë“ˆ í• ë‹¹
  â”œâ”€ adata.var['hotspot_autocorr']: ìê¸°ìƒê´€ê°’
  â””â”€ ë™ì  ìˆœì„œ ì •ë³´
```

### ì‹¤í–‰ ì½”ë“œ

```python
# HOTSPOT ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
import hotspot

# 1. HOTSPOT ê°ì²´ ìƒì„±
hs = hotspot.Hotspot(
    adata,
    layer_key=None,        # ì‚¬ìš©í•  ë ˆì´ì–´
    model='normal'         # 'normal', 'bernoulli', 'negative_binomial'
)

# 2. kNN ê·¸ë˜í”„ ê³„ì‚°
hs.create_knn_graph(
    weighted_knn=True,
    n_neighbors=15,        # k ê°’
    n_jobs=8
)

# 3. ìê¸°ìƒê´€ ê³„ì‚°
hs.compute_autocorrelation(
    jobs=8
)

# 4. ëª¨ë“ˆ ì‹ë³„
hs.compute_modules(
    min_gene_threshold=5,  # ìµœì†Œ ìœ ì „ì ìˆ˜
    core_only=False
)

# 5. ê²°ê³¼ ì¶”ì¶œ
modules = hs.modules.copy()
print(f"Found {modules['module'].nunique()} modules")

# 6. ëª¨ë“ˆ ë³„ ìƒìœ„ ìœ ì „ì
for mod in modules['module'].unique():
    mod_genes = modules[modules['module'] == mod].head(10)
    print(f"\nModule {mod} genes: {mod_genes.index.tolist()}")

# 7. ë™ì  ìˆœì„œ (ì§€ì—° ìƒê´€)
hs.compute_left_right_annotation(
    annotation='spatial_x'  # ê³µê°„ ì¢Œí‘œ ê¸°ë°˜
)
```

### ë…íŠ¹í•œ íŠ¹ì§•

**ì¥ì **:
- ì‹œê°„ ì—­í•™ í¬ì°© ê°€ëŠ¥
- ë™ì  í”„ë¡œì„¸ìŠ¤ ëª¨ë¸ë§
- ì¸ê³¼ êµ¬ì¡° ì¶”ë¡ 

**ë‹¨ì **:
- ë³µì¡í•œ ì„¤ì •
- ê³„ì‚° ì‹œê°„ ê¸¸ìŒ
- í•´ì„ ì–´ë ¤ì›€

---

## 5ï¸âƒ£ SOMDE (ìì¡°ì§í™” ë§µ + ë°€ë„ ì¶”ì •)

### íŒŒì¼ ìœ„ì¹˜
- `8_1_SOMDE.ipynb`

### ê°œë…

SOMDEëŠ” **ìì¡°ì§í™” ë§µ(Self-Organizing Map, SOM)**ìœ¼ë¡œ ìœ ì „ìë¥¼ ì €ì°¨ì› ê³µê°„ì— ë§¤í•‘í•œ í›„, ê³µê°„ì—ì„œ ë°€ë„ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ê³ ì°¨ì› ìœ ì „ì ë°œí˜„ â†’ 2D SOMìœ¼ë¡œ ì¶•ì†Œ
- SOM ìƒì˜ ìœ ì „ìë“¤ì˜ ê³µê°„ ë¶„í¬ ë¶„ì„
- ë°€ë„ê°€ ë†’ì€ ì˜ì—­ì´ ê¸°ëŠ¥ì ìœ¼ë¡œ ìœ ì‚¬í•œ ìœ ì „ì ê·¸ë£¹

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥: adata_spatial
      â”œâ”€ adata.X: ì •ê·œí™”ëœ ë°œí˜„
      â””â”€ adata.obsm['spatial']: ê³µê°„ ì¢Œí‘œ

1ë‹¨ê³„: ìì¡°ì§í™” ë§µ í•™ìŠµ
  â†’ SOM ê·¸ë¦¬ë“œ (ì˜ˆ: 10x10)
  â†’ ê° ìœ ì „ìë¥¼ SOM ë‰´ëŸ°ì— í• ë‹¹

2ë‹¨ê³„: ë°€ë„ ì¶”ì •
  â†’ SOM ìƒì—ì„œ ìœ ì „ì ë°€ë„ ê³„ì‚°
  â†’ êµ­ì†Œ ì˜ì—­ ì‹ë³„

3ë‹¨ê³„: SVF ìŠ¤ì½”ì–´ë§
  â†’ SOMì˜ ê³µê°„ ìœ„ì¹˜ vs ì‹¤ì œ ê³µê°„ì˜ ë°œí˜„ íŒ¨í„´ ë¹„êµ

4ë‹¨ê³„: ìœ ì˜ì„± íŒì •
  â†’ ìˆœì—´ ê²€ì •ìœ¼ë¡œ p-value ê³„ì‚°

ì¶œë ¥: SVF ìœ ì „ì ë¦¬ìŠ¤íŠ¸ ë° ìŠ¤ì½”ì–´
```

### ì‹¤í–‰ ì½”ë“œ

```python
# SOMDE ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
import somde

# 1. SOMDE ê°ì²´ ìƒì„±
somde_obj = somde.SOMDE(
    adata=adata,
    spatial_key='spatial'
)

# 2. SOM í•™ìŠµ
somde_obj.train_som(
    grid_size=(10, 10),    # â˜… SOM ê·¸ë¦¬ë“œ í¬ê¸°
    epochs=100,
    learning_rate=0.3
)

# 3. ë°€ë„ ê¸°ë°˜ SVF ê³„ì‚°
somde_obj.compute_svf(
    n_perms=1000,
    scale_factor=1.0
)

# 4. ê²°ê³¼ ì¶”ì¶œ
svf_scores = somde_obj.svf_scores.copy()
svf_scores = svf_scores.sort_values('p_value')

# 5. ìƒìœ„ SVF ìœ ì „ì
top_svf = svf_scores[svf_scores['p_value'] < 0.05]
print(f"Found {len(top_svf)} SVF genes")
print(top_svf.head(20))
```

### íŒŒë¼ë¯¸í„° í•´ì„

- **grid_size = (10, 10)**: SOM í¬ê¸°
  - ì‘ìŒ: ë¹ ë¥´ì§€ë§Œ ì •ë³´ ì†ì‹¤
  - ì¤‘ê°„: ê· í˜• (ê¶Œì¥)
  - í¼: ìƒì„¸í•˜ì§€ë§Œ ëŠë¦¼
- **epochs = 100**: í•™ìŠµ ë°˜ë³µ
- **n_perms = 1000**: ìˆœì—´ ê²€ì • ë°˜ë³µ

---

## 6ï¸âƒ£ Sinfonia (ì‹ ê²½ë§ + ìê¸°ì§€ë„ í•™ìŠµ)

### íŒŒì¼ ìœ„ì¹˜
- `8_1_Sinfonia.ipynb`

### ê°œë…

SinfoniaëŠ” **ìê¸°ì§€ë„ ì‹ ê²½ë§(Self-Supervised Neural Networks)**ì„ ì‚¬ìš©í•˜ì—¬ ê³µê°„ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ì…ë ¥: ì†ìƒëœ(noisy) ë°œí˜„ ë°ì´í„°
- í•™ìŠµ ëª©í‘œ: ì†ìƒë˜ì§€ ì•Šì€ ì›ë³¸ ë³µì›
- ê³µê°„ ì‹ í˜¸ë§Œ ì†ìƒëœ ì…ë ¥ ë³µì›ì— ë„ì›€ë¨
- ë³µì› ì˜¤ë¥˜ í¬ê¸° = SVF ì •ë„

### ë…¸íŠ¸ë¶ êµ¬ì¡°

```
ì…ë ¥: adata_spatial
      â”œâ”€ adata.X: ì •ê·œí™”ëœ ë°œí˜„
      â”œâ”€ adata.obsm['spatial']: ê³µê°„ ì¢Œí‘œ
      â””â”€ ê³µê°„ ì´ì›ƒ ê·¸ë˜í”„

1ë‹¨ê³„: ì†ìƒ ì „ëµ ì„ íƒ
  â†’ Gaussian noise, dropout, masking

2ë‹¨ê³„: ì¸ì½”ë”-ë””ì½”ë” ì‹ ê²½ë§
  â†’ ì…ë ¥ (ì†ìƒëœ X) â†’ ì¸ì½”ë” â†’ ë””ì½”ë” â†’ ì¶œë ¥

3ë‹¨ê³„: ê³µê°„ ì •ê·œí™”
  â†’ ì´ì›ƒ ì…€ë“¤ì˜ ë°œí˜„ ìœ ì‚¬ì„± ê°•ì œ

4ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨
  â†’ Loss = reconstruction_loss + spatial_regularization

5ë‹¨ê³„: SVF ìŠ¤ì½”ì–´
  â†’ ë³µì› ì˜¤ë¥˜ ì—­ì •ê·œí™”ë¡œ ê³µê°„ì„± ìŠ¤ì½”ì–´ ê³„ì‚°

ì¶œë ¥: SVF ìœ ì „ì ë° ì‹ ë¢°ë„ ì ìˆ˜
```

### ì‹¤í–‰ ì½”ë“œ

```python
# Sinfonia ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
from sinfonia import Sinfonia

# 1. Sinfonia ëª¨ë¸ ìƒì„±
model = Sinfonia(
    adata=adata,
    spatial_key='spatial',
    n_latent=32,           # ì ì¬ ì°¨ì›
    noise_type='gaussian', # 'gaussian', 'dropout', 'mask'
    noise_level=0.2        # ë…¸ì´ì¦ˆ ê°•ë„ (20%)
)

# 2. ëª¨ë¸ í›ˆë ¨
model.train(
    epochs=200,
    batch_size=32,
    learning_rate=0.001,
    lambda_spatial=0.5,    # ê³µê°„ ì •ê·œí™” ê°•ë„
    early_stopping=True,
    patience=20,
    device='cuda'
)

# 3. SVF ê³„ì‚°
svf_scores = model.compute_svf()

# 4. ê²°ê³¼ ì •ë ¬
svf_df = pd.DataFrame({
    'gene': adata.var_names,
    'svf_score': svf_scores,
    'p_value': model.get_pvalues()
})
svf_df = svf_df.sort_values('svf_score', ascending=False)

# 5. ìƒìœ„ SVF ìœ ì „ì
sig_svf = svf_df[svf_df['p_value'] < 0.05]
print(f"Found {len(sig_svf)} SVF genes")
print(sig_svf.head(30))

# 6. ì‹œê°í™”
import matplotlib.pyplot as plt
plt.scatter(svf_df['svf_score'], -np.log10(svf_df['p_value']), alpha=0.5)
plt.axhline(y=-np.log10(0.05), color='r', label='p=0.05')
plt.xlabel('SVF Score')
plt.ylabel('-log10(p-value)')
plt.legend()
plt.show()
```

### íŠ¹ì§•

**ì¥ì **:
- ìµœì‹  ë°©ë²•, ë†’ì€ ì •í™•ë„
- ìœ ì—°í•œ ë…¸ì´ì¦ˆ ì „ëµ
- í•´ì„ ê°€ëŠ¥í•œ ê³µê°„ ì •ê·œí™”

**ë‹¨ì **:
- í•™ìŠµ ì‹œê°„ í•„ìš” (1~2ì‹œê°„)
- GPU ê¶Œì¥
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìš”

---

## 7ï¸âƒ£ Seurat (R/Monocle + Moran's I ë³€í˜•)

### íŒŒì¼ ìœ„ì¹˜
- `8_1_Seurat_spatial_feature_loading.R`
- `8_1_Seurat_spatial_feature_loading_with_timing.R`

### ê°œë…

Seuratì˜ ê³µê°„ ê¸°ëŠ¥ì€ **Moran's Ië¥¼ ê¸°ë°˜ìœ¼ë¡œ** Seuratì˜ íŠ¹í™”ëœ êµ¬í˜„ì…ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- FindSpatiallyVariableFeatures() í•¨ìˆ˜ë¡œ í•œ ë²ˆì— ê³„ì‚°
- assay='Spatial'ë¡œ ì›ë³¸ ì¹´ìš´íŠ¸ ì‚¬ìš©
- spatial.mode='markvariogram'ë„ ì˜µì…˜ìœ¼ë¡œ ì œê³µ

### R ì½”ë“œ ì˜ˆì‹œ

```r
# Seurat ê³µê°„ SVF ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
library(Seurat)

# 1. Seurat ê°ì²´ ë¡œë”©
seurat_obj <- readRDS('seurat_obj.rds')

# 2. ê³µê°„ SVF ê³„ì‚°
seurat_obj <- FindSpatiallyVariableFeatures(
    object=seurat_obj,
    assay='Spatial',
    features=VariableFeatures(seurat_obj),
    selection.method='markvariogram',  # ë˜ëŠ” 'moransi'
    verbose=TRUE
)

# 3. ìƒìœ„ SVF ìœ ì „ì ì¶”ì¶œ
top_spatially_var_features <- head(
    SpatiallyVariableFeatures(seurat_obj, selection.method='markvariogram'),
    20
)
print(top_spatially_var_features)

# 4. ì‹œê°í™”
pdf('seurat_svf_plot.pdf', width=12, height=8)
SpatialFeaturePlot(
    object=seurat_obj,
    features=top_spatially_var_features,
    ncol=4,
    stroke=0.1
)
dev.off()

# 5. ê²°ê³¼ ì €ì¥
metadata <- seurat_obj@meta.data
svf_scores <- data.frame(
    gene=rownames(seurat_obj),
    markvariogram=rowData(seurat_obj)$markvariogram_score
)
```

---

## 8ï¸âƒ£ Giotto (ê³µê°„ ìƒê´€ í…ŒìŠ¤íŠ¸ + ë‹¤ì¤‘ ìƒ˜í”Œ)

### íŒŒì¼ ìœ„ì¹˜
- `8_1_Giotto_spatial_genes.R`
- `8_1_Giotto_spatial_genes_multi_section.R`

### ê°œë…

GiottoëŠ” **ê³µê°„ ìƒê´€ í…ŒìŠ¤íŠ¸(Spatial Correlation Test)**ë¥¼ ì‚¬ìš©í•˜ë©°, **ë‹¤ì¤‘ ì„¹ì…˜ ë¶„ì„**ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì§€ì›í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ê·¸ë˜í”„ ê¸°ë°˜ ê³µê°„ ìƒê´€
- ë‹¤ì¤‘ ìƒ˜í”Œ ë©”íƒ€ ë¶„ì„
- ê°•ê±´í•œ í†µê³„ì  ê²€ì •

### R ì½”ë“œ ì˜ˆì‹œ

```r
# Giotto ì‹¤í–‰ ì½”ë“œ ì˜ˆì‹œ
library(Giotto)

# 1. Giotto ê°ì²´ ìƒì„±
giotto_obj <- createGiottoObject(
    raw_exprs=expression_matrix,
    spatial_locs=spatial_coordinates,
    instructions=giotto_instructions
)

# 2. ì „ì²˜ë¦¬
giotto_obj <- normalizeGiotto(giotto_obj)
giotto_obj <- addStatistics(giotto_obj)

# 3. ê³µê°„ SVF ê³„ì‚°
giotto_obj <- binSpect(
    gobject=giotto_obj,
    bin_method='kmeans',
    do_fisher_test=TRUE,
    nrand=100,             # ë¬´ì‘ìœ„ ìˆœì—´ ìˆ˜
    p_adjust_method='bonferroni',
    verbose=TRUE
)

# 4. ë‹¤ì¤‘ ìƒ˜í”Œ ë¶„ì„ (ì—¬ëŸ¬ ì„¹ì…˜)
all_results <- list()
for (sample in sample_list) {
    all_results[[sample]] <- binSpect(giotto_list[[sample]])
}

# 5. ë©”íƒ€ ë¶„ì„ (êµì§‘í•© SVF)
meta_svf <- Reduce(intersect, lapply(all_results, function(x) x$genes[x$p_value < 0.05]))
print(paste("Consensus SVF genes:", length(meta_svf)))

# 6. ê²°ê³¼ ì‹œê°í™”
plotSpatialFeatures(
    gobject=giotto_obj,
    features=head(meta_svf, 12),
    cow_n_col=3
)
```

---

## ë¹„êµ ë¶„ì„ ë…¸íŠ¸ë¶: 8_2_comparison_between_SVFs.ipynb

### ê°œìš”

21ê°œ ë°ì´í„°ì„¸íŠ¸ì— ê±¸ì³ 8ê°€ì§€ SVF ë°©ë²•ì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.

### ë¹„êµ ì§€í‘œ

```python
# ì£¼ìš” í‰ê°€ ì§€í‘œ

# 1. ë°©ë²• ê°„ í•©ì˜ë„ (Agreement)
def compute_agreement(methods_results):
    """ë‹¤ì–‘í•œ ë°©ë²•ì´ ì°¾ì€ SVF ìœ ì „ìì˜ êµì§‘í•©"""
    top_n = 100  # ê° ë°©ë²•ë³„ ìƒìœ„ 100ê°œ

    results_dict = {}
    for method, genes in methods_results.items():
        results_dict[method] = set(genes[:top_n])

    # Pairwise Jaccard Index
    agreement_matrix = np.zeros((len(methods_results), len(methods_results)))
    methods_list = list(methods_results.keys())

    for i, m1 in enumerate(methods_list):
        for j, m2 in enumerate(methods_list):
            if i == j:
                agreement_matrix[i, j] = 1.0
            else:
                intersection = len(results_dict[m1] & results_dict[m2])
                union = len(results_dict[m1] | results_dict[m2])
                jaccard = intersection / union
                agreement_matrix[i, j] = jaccard

    return agreement_matrix

# 2. ì „ì‚° ì‹œê°„ (Runtime)
times = {
    'Moran_I': 0.5,      # ë¶„
    'Geary_C': 0.8,
    'SpatialDE': 30,
    'HOTSPOT': 5,
    'SOMDE': 10,
    'Sinfonia': 120,
    'Seurat': 2,
    'Giotto': 8
}

# 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (Memory)
memory = {
    'Moran_I': 1,       # GB
    'Geary_C': 1,
    'SpatialDE': 4,
    'HOTSPOT': 3,
    'SOMDE': 2,
    'Sinfonia': 8,
    'Seurat': 2,
    'Giotto': 5
}
```

### ë¹„êµ ê²°ê³¼ ìš”ì•½

| ë°©ë²• | ì •í™•ë„ | í•©ì˜ë„ | ì†ë„ | ë©”ëª¨ë¦¬ | ê¶Œì¥ |
|------|--------|--------|------|---------|------|
| **Moran's I** | â­â­â­ | 0.65 | â­â­â­â­â­ | â­â­â­â­â­ | ë¹ ë¥¸ íƒìƒ‰ |
| **Geary's C** | â­â­â­â­ | 0.62 | â­â­â­â­â­ | â­â­â­â­â­ | ê²½ê³„ ì°¾ê¸° |
| **SpatialDE** | â­â­â­â­â­ | 0.72 | â­ | â­â­â­ | ìµœê³  ì •í™•ë„ |
| **HOTSPOT** | â­â­â­â­ | 0.68 | â­â­â­ | â­â­â­ | ë™ì  ë¶„ì„ |
| **SOMDE** | â­â­â­â­ | 0.70 | â­â­ | â­â­â­ | ëª¨ë“ˆ íƒìƒ‰ |
| **Sinfonia** | â­â­â­â­â­ | 0.75 | â­ | â­ | ë†’ì€ ì •í™•ë„ |
| **Seurat** | â­â­â­â­ | 0.68 | â­â­â­â­ | â­â­â­â­ | R ì‚¬ìš©ì |
| **Giotto** | â­â­â­â­ | 0.69 | â­â­â­ | â­â­â­ | ë‹¤ì¤‘ ìƒ˜í”Œ |

### ì„ íƒ ê°€ì´ë“œ

```
ìƒí™©ë³„ ê¶Œì¥ ë°©ë²•:

1ï¸âƒ£ ë¹ ë¥¸ íƒìƒ‰ (1ë¶„ ì´ë‚´)
   â†’ Moran's I ë˜ëŠ” Geary's C

2ï¸âƒ£ ë†’ì€ ì •í™•ë„ ì¤‘ì‹œ
   â†’ SpatialDE ë˜ëŠ” Sinfonia

3ï¸âƒ£ ê²½ê³„ ê°•ì¡°
   â†’ Geary's C + ë†’ì€ p-value ì„ê³„ê°’

4ï¸âƒ£ ë™ì  í”„ë¡œì„¸ìŠ¤
   â†’ HOTSPOT (ì‹œê°„ ì—­í•™ ìˆëŠ” ë°ì´í„°)

5ï¸âƒ£ ì—¬ëŸ¬ ìƒ˜í”Œ ë¶„ì„
   â†’ Giotto (ë‹¤ì¤‘ ì„¹ì…˜ ë©”íƒ€ë¶„ì„)

6ï¸âƒ£ R ê¸°ë°˜ íŒŒì´í”„ë¼ì¸
   â†’ Seurat ë˜ëŠ” Giotto

7ï¸âƒ£ Python í†µí•© í•„ìš”
   â†’ Squidpy (Moran/Geary) ë˜ëŠ” SpatialDE
```

---

## ìµœì¢… í†µí•© ì›Œí¬í”Œë¡œìš°

```
SVF ë¶„ì„ ì™„ì „ ê°€ì´ë“œ:

STEP 1: ë¹ ë¥¸ ìŠ¤í¬ë¦¬ë‹ (5ë¶„)
â”œâ”€ Squidpy Moran's I ì‹¤í–‰
â””â”€ ìƒìœ„ 500ê°œ í›„ë³´ ìœ ì „ì ì„ ë³„

STEP 2: ë°©ë²• ë¹„êµ (1ì‹œê°„)
â”œâ”€ SpatialDE ì •ë°€ ë¶„ì„
â”œâ”€ Geary's C ê²½ê³„ ê°ì§€
â””â”€ ê²°ê³¼ í†µí•© (Venn diagram)

STEP 3: ì‹¬í™” ë¶„ì„ (ì„ íƒ)
â”œâ”€ HOTSPOTìœ¼ë¡œ ë™ì  ëª¨ë“ˆ ì°¾ê¸°
â””â”€ Sinfoniaë¡œ ì‹ ê²½ë§ ê¸°ë°˜ ê²€ì¦

STEP 4: ë‹¤ì¤‘ ìƒ˜í”Œ ê²€ì¦ (ì˜µì…˜)
â”œâ”€ Giottoë¡œ ë©”íƒ€ SVF ì‹ë³„
â””â”€ ê³µí†µ ìƒë¬¼í•™ì  ì‹ í˜¸ í™•ì¸

ê²°ê³¼: ê³ ì‹ ë¢°ë„ SVF ìœ ì „ì ì„¸íŠ¸
```

---

